{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "OC4n2o5bQj7q"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime, timezone\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from googleapiclient.discovery import build\n",
    "import google.generativeai as genai\n",
    "from youtube_transcript_api import YouTubeTranscriptApi, NoTranscriptFound, TranscriptsDisabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "i548yweyQpeV"
   },
   "outputs": [],
   "source": [
    "YOUTUBE_API_KEY = \"AIzaSyBP9csKRKy6xUrKYn7ovmRcAiNn7pZhW1k\"  # Replace with your YouTube Data API Key\n",
    "GEMINI_API_KEY = \"AIzaSyCVFKZOqUpoIz75Oi9fOmgtF42S49GIFD8\"    # Replace with your Gemini API Key\n",
    "DB_PATH = 'beauty_blueprint.db'\n",
    "\n",
    "# Initialize Gemini AI\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "# Using gemini-2.0-flash for multimodal capabilities and efficiency\n",
    "GEMINI_MULTIMODAL_MODEL = 'gemini-2.0-flash'\n",
    "GEMINI_TEXT_MODEL = 'gemini-2.0-flash'\n",
    "\n",
    "# Search Queries (from your search query list.docx)\n",
    "SEARCH_QUERIES = [\n",
    "    'makeup artist'\n",
    "    # 'beauty blogger', 'makeup guru', 'beauty influencer', 'makeup channel',\n",
    "    # 'american makeup artist', 'us beauty blogger', 'english speaking makeup artist',\n",
    "    # 'north american makeup channel', 'natural makeup artist', 'glam makeup channel',\n",
    "    # 'editorial makeup artist', 'bridal makeup channel', 'everyday makeup tutorial channel',\n",
    "    # 'clean beauty influencer', 'affordable makeup channel', 'luxury beauty guru',\n",
    "    # 'skincare and makeup channel', 'pro makeup techniques channel',\n",
    "    # 'makeup tips and tricks channel', 'south asian makeup artist', 'indian makeup channel',\n",
    "    # 'desilook makeup', 'east asian makeup tutorial channel', 'korean makeup artist us',\n",
    "    # 'japanese makeup channel usa', 'black makeup artist', 'african american beauty guru',\n",
    "    # 'dark skin makeup channel', 'latinx beauty blogger', 'hispanic makeup artist',\n",
    "    # 'latina beauty channel', 'white makeup artist', 'caucasian beauty blogger',\n",
    "    # 'american beauty channel'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "fnlpo6THQsvc"
   },
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "\n",
    "# Predefined Categories (from your Table Schema.docx)\n",
    "PREDEFINED_CATEGORIES = {\n",
    "    \"face_shape\": [\"round_face\", \"oval_face\", \"square_face\", \"heart_face\", \"long_face\", \"diamond_face\"],\n",
    "    \"eye_shape\": [\"hooded_eyes\", \"almond_eyes\", \"round_eyes\", \"downturned_eyes\", \"monolid_eyes\",\n",
    "                  \"up-turned_eyes\", \"deep_set_eyes\", \"close_set_eyes\", \"wide_set_eyes\"],\n",
    "    \"skin_undertone\": [\"warm_undertone\", \"cool_undertone\", \"neutral_undertone\"],\n",
    "    \"skin_type_concerns\": [\"oily_skin\", \"dry_skin\", \"combination_skin\", \"acne_prone_skin\",\n",
    "                           \"sensitive_skin\", \"mature_skin\"],\n",
    "    \"lip_shape\": [\"fuller_lips\", \"thin_lips\", \"heart_shaped_lips\", \"bow_shaped_lips\"],\n",
    "    \"other_features\": [\"narrow_nose\", \"wide_nose\", \"high_cheeks\", \"low_cheeks\"],\n",
    "    \"primary_makeup_style\": [\"natural\", \"everyday\", \"glam\", \"editorial\", \"bridal\", \"dramatic\",\n",
    "                             \"minimalist\", \"soft_glam\", \"no_makeup_makeup\"],\n",
    "    \"target_skill_level\": [\"beginner\", \"intermediate\", \"advanced\", \"pro_artist\"],\n",
    "    \"demographic_focus\": [\"teen_focused\", \"adult_focused\", \"mature_age_focused\", \"dark_skin_tones\",\n",
    "                          \"light_skin_tones\", \"male_makeup\", \"non_binary_makeup\"],\n",
    "    \"llm_thumbnail_face_shape\": [\"Round\", \"Oval\", \"Square\", \"Heart\", \"Long\", \"Diamond\", \"unknown\"],\n",
    "    \"llm_thumbnail_skin_color\": [\"fair\", \"light\", \"medium\", \"tan\", \"dark\", \"deep\", \"unknown\"],\n",
    "    \"llm_thumbnail_eye_shape\": [\"Almond\", \"Round\", \"Hooded\", \"Monolid\", \"Downturned\", \"Up-turned\",\n",
    "                                 \"Deep-set\", \"Close-set\", \"Wide-set\", \"unknown\"],\n",
    "    \"llm_thumbnail_lip_shape\": [\"Fuller\", \"Thin\", \"Heart\", \"Bow\", \"unknown\"],\n",
    "    \"llm_thumbnail_status\": [\"analyzed\", \"skipped_multiple_faces\", \"skipped_no_clear_face\",\n",
    "                             \"error_processing_image\", \"error_llm_response\", \"pending\", \"unknown\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "DBoQDIrMQxbd"
   },
   "outputs": [],
   "source": [
    "# --- Database Functions ---\n",
    "def create_channels_table(db_path=DB_PATH):\n",
    "    \"\"\"\n",
    "    Creates an SQLite database and the 'channels' table within it.\n",
    "    \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        create_table_sql = \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS channels_new (\n",
    "            channel_id                      TEXT PRIMARY KEY,\n",
    "            channel_name                    TEXT NOT NULL,\n",
    "            channel_url                     TEXT,\n",
    "            channel_description             TEXT,\n",
    "            published_at                    TEXT,\n",
    "            profile_picture_url             TEXT,\n",
    "            subscriber_count                INTEGER,\n",
    "            video_count                     INTEGER,\n",
    "            total_view_count                INTEGER,\n",
    "            country                         TEXT,\n",
    "            default_language                TEXT, -- New column for channel's default language\n",
    "            keywords                        TEXT, -- New column for channel keywords (JSON array string)\n",
    "            topic_ids                       TEXT,\n",
    "            last_content_upload_at          TEXT,\n",
    "            last_updated                    TEXT,\n",
    "            features_aligned_with           TEXT,\n",
    "            primary_makeup_style            TEXT,\n",
    "            target_skill_level              TEXT,\n",
    "            demographic_focus               TEXT,\n",
    "            llm_thumbnail_face_shape        TEXT,\n",
    "            llm_thumbnail_skin_color        TEXT,\n",
    "            llm_thumbnail_eye_shape         TEXT,\n",
    "            llm_thumbnail_lip_shape         TEXT,\n",
    "            llm_thumbnail_status            TEXT,\n",
    "            llm_thumbnail_analysis_date     TEXT\n",
    "        );\n",
    "        \"\"\"\n",
    "        cursor.execute(create_table_sql)\n",
    "        conn.commit()\n",
    "        print(f\"Table 'channels' created successfully in {db_path} or already exists.\")\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"Database error: {e}\")\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "hILZbhSEQ4KL"
   },
   "outputs": [],
   "source": [
    "def insert_channel_data(channel_data, db_path=DB_PATH):\n",
    "    \"\"\"\n",
    "    Inserts or updates channel data into the 'channels' table.\n",
    "    \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        columns = ', '.join(channel_data.keys())\n",
    "        placeholders = ', '.join(['?' for _ in channel_data.keys()])\n",
    "        update_placeholders = ', '.join([f\"{key} = ?\" for key in channel_data.keys() if key != 'channel_id'])\n",
    "\n",
    "        # Using INSERT OR REPLACE to handle both inserts and updates based on channel_id\n",
    "        # This will replace an existing row if channel_id matches.\n",
    "        insert_sql = f\"\"\"\n",
    "        INSERT OR REPLACE INTO channels ({columns}) VALUES ({placeholders})\n",
    "        \"\"\"\n",
    "        # For simplicity, if we only need to update specific fields, a more targeted UPDATE\n",
    "        # statement might be better, but INSERT OR REPLACE is fine for full record upserts.\n",
    "\n",
    "        cursor.execute(insert_sql, tuple(channel_data.values()))\n",
    "        conn.commit()\n",
    "        # print(f\"Channel '{channel_data.get('channel_name', 'Unknown')}' inserted/updated.\")\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"Error inserting/updating channel data: {e}\")\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "xIk4BCn9Q64H"
   },
   "outputs": [],
   "source": [
    "# --- YouTube API Functions ---\n",
    "def get_youtube_service():\n",
    "    \"\"\"Builds and returns a YouTube Data API service object.\"\"\"\n",
    "    return build('youtube', 'v3', developerKey=YOUTUBE_API_KEY)\n",
    "\n",
    "def search_youtube_channels(youtube, query, region_code='US', max_results=20):\n",
    "    \"\"\"Searches for YouTube channels based on a query.\"\"\"\n",
    "    channels = []\n",
    "    try:\n",
    "        search_response = youtube.search().list(\n",
    "            q=query,\n",
    "            type='channel',\n",
    "            part='id,snippet',\n",
    "            maxResults=max_results,\n",
    "            regionCode=region_code\n",
    "        ).execute()\n",
    "\n",
    "        for item in search_response.get('items', []):\n",
    "            channel_id = item['id']['channelId']\n",
    "            channel_name = item['snippet']['title']\n",
    "            channel_description = item['snippet']['description']\n",
    "            published_at = item['snippet']['publishedAt']\n",
    "            profile_picture_url = item['snippet']['thumbnails']['high']['url']\n",
    "            country = item['snippet'].get('country') # Country might not always be present\n",
    "            default_language = item['snippet'].get('defaultLanguage') # Added default language\n",
    "            print(\"channel_id :\",channel_id)\n",
    "            # --- MODIFIED LOGIC HERE ---\n",
    "            # Include channels where country is explicitly 'US' or if country is not specified\n",
    "            # (as regionCode='US' search implies a US bias, even if country field is missing)\n",
    "            if country == 'US' or country is None:\n",
    "                channels.append({\n",
    "                    'channel_id': channel_id,\n",
    "                    'channel_name': channel_name,\n",
    "                    'channel_description': channel_description,\n",
    "                    'published_at': published_at,\n",
    "                    'profile_picture_url': profile_picture_url,\n",
    "                    'default_language': default_language,\n",
    "                    'country': country, # Keep the actual country value (could be None)\n",
    "                    'uploads_playlist_id': None # Placeholder, will be fetched later\n",
    "                })\n",
    "    except Exception as e:\n",
    "        print(f\"Error searching channels for query '{query}': {e}\")\n",
    "    return channels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "L5_3T2XlQ_vl"
   },
   "outputs": [],
   "source": [
    "def get_channel_statistics_and_topics(youtube, channel_ids):\n",
    "    \"\"\"Fetches statistics, topic details, and branding settings for given channel IDs.\"\"\"\n",
    "    if not channel_ids:\n",
    "        return {}\n",
    "\n",
    "    details = {}\n",
    "    # YouTube API allows up to 50 IDs per request for channels.list\n",
    "    id_chunks = [channel_ids[i:i + 50] for i in range(0, len(channel_ids), 50)]\n",
    "\n",
    "    for chunk in id_chunks:\n",
    "        try:\n",
    "            channels_response = youtube.channels().list(\n",
    "                part='statistics,topicDetails,contentDetails,brandingSettings', # Added brandingSettings\n",
    "                id=','.join(chunk)\n",
    "            ).execute()\n",
    "\n",
    "            for item in channels_response.get('items', []):\n",
    "                channel_id = item['id']\n",
    "                stats = item.get('statistics', {})\n",
    "                topic_details = item.get('topicDetails', {})\n",
    "                content_details = item.get('contentDetails', {})\n",
    "                branding_settings = item.get('brandingSettings', {}).get('channel', {}) # Get channel branding settings\n",
    "\n",
    "                details[channel_id] = {\n",
    "                    'subscriber_count': int(stats.get('subscriberCount', 0)),\n",
    "                    'video_count': int(stats.get('videoCount', 0)),\n",
    "                    'total_view_count': int(stats.get('viewCount', 0)),\n",
    "                    'topic_ids': topic_details.get('topicIds', []),\n",
    "                    'uploads_playlist_id': content_details.get('relatedPlaylists', {}).get('uploads'),\n",
    "                    'keywords': branding_settings.get('keywords', []) # Added keywords\n",
    "                }\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching details for channel IDs {chunk}: {e}\")\n",
    "    return details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "oEV3XDG7RC4n"
   },
   "outputs": [],
   "source": [
    "def get_last_video_upload_timestamp(youtube, uploads_playlist_id):\n",
    "    \"\"\"Fetches the timestamp of the most recent video in an uploads playlist.\"\"\"\n",
    "    if not uploads_playlist_id:\n",
    "        return None\n",
    "    try:\n",
    "        playlist_items_response = youtube.playlistItems().list(\n",
    "            part='snippet',\n",
    "            playlistId=uploads_playlist_id,\n",
    "            maxResults=1, # We only need the latest one\n",
    "            fields='items/snippet/publishedAt'\n",
    "        ).execute()\n",
    "\n",
    "        if playlist_items_response.get('items'):\n",
    "            # The API returns items in reverse chronological order by default for playlists\n",
    "            # so the first item is the most recent.\n",
    "            return playlist_items_response['items'][0]['snippet']['publishedAt']\n",
    "    except Exception as e:\n",
    "        # print(f\"Error fetching last upload timestamp for playlist {uploads_playlist_id}: {e}\")\n",
    "        pass # Gracefully handle cases where playlist might be empty or restricted\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "L5vAIETxRF0o"
   },
   "outputs": [],
   "source": [
    "# --- Gemini AI Functions ---\n",
    "def get_image_as_base64(image_url):\n",
    "    \"\"\"Downloads an image and returns its Base64 encoded string.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(image_url, timeout=10)\n",
    "        response.raise_for_status() # Raise an exception for HTTP errors (4xx or 5xx)\n",
    "\n",
    "        img_data = BytesIO(response.content)\n",
    "        img = Image.open(img_data)\n",
    "\n",
    "        # Convert to RGB if not already (some images might be RGBA, P, etc.)\n",
    "        if img.mode != 'RGB':\n",
    "            img = img.convert('RGB')\n",
    "\n",
    "        # Resize for faster processing and to avoid exceeding token limits if images are huge\n",
    "        # Max dimension 512-1024px is usually good for LLMs\n",
    "        max_dim = 512\n",
    "        if max(img.size) > max_dim:\n",
    "            img.thumbnail((max_dim, max_dim), Image.LANCZOS) # LANCZOS is a high-quality downsampling filter\n",
    "\n",
    "        buffered = BytesIO()\n",
    "        img.save(buffered, format=\"JPEG\") # Use JPEG for smaller size\n",
    "        import base64 # Import base64 here to avoid circular dependency with PIL\n",
    "        return base64.b64encode(buffered.getvalue()).decode('utf-8')\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error downloading image {image_url}: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image {image_url}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "vDlnzXW_RKO7"
   },
   "outputs": [],
   "source": [
    "def analyze_thumbnail_with_gemini(image_base64):\n",
    "    \"\"\"\n",
    "    Analyzes a thumbnail image with Gemini AI to infer facial attributes.\n",
    "    Returns a dictionary of inferred attributes and status.\n",
    "    \"\"\"\n",
    "    model = genai.GenerativeModel(GEMINI_MULTIMODAL_MODEL)\n",
    "    response_data = {\n",
    "        \"llm_thumbnail_face_shape\": \"unknown\",\n",
    "        \"llm_thumbnail_skin_color\": \"unknown\",\n",
    "        \"llm_thumbnail_eye_shape\": \"unknown\",\n",
    "        \"llm_thumbnail_lip_shape\": \"unknown\",\n",
    "        \"llm_thumbnail_status\": \"unknown\"\n",
    "    }\n",
    "\n",
    "    if not image_base64:\n",
    "        response_data[\"llm_thumbnail_status\"] = \"error_processing_image\"\n",
    "        return response_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "feUyn-ZZRXXi"
   },
   "outputs": [],
   "source": [
    "def analyze_thumbnail_with_gemini(image_base64):\n",
    "    \"\"\"\n",
    "    Analyzes a thumbnail image with Gemini AI to infer facial attributes.\n",
    "    Returns a dictionary of inferred attributes and status.\n",
    "    \"\"\"\n",
    "    model = genai.GenerativeModel(GEMINI_MULTIMODAL_MODEL)\n",
    "    response_data = {\n",
    "        \"llm_thumbnail_face_shape\": \"unknown\",\n",
    "        \"llm_thumbnail_skin_color\": \"unknown\",\n",
    "        \"llm_thumbnail_eye_shape\": \"unknown\",\n",
    "        \"llm_thumbnail_lip_shape\": \"unknown\",\n",
    "        \"llm_thumbnail_status\": \"unknown\"\n",
    "    }\n",
    "\n",
    "    if not image_base64:\n",
    "        response_data[\"llm_thumbnail_status\"] = \"error_processing_image\"\n",
    "        return response_data\n",
    "\n",
    "    # Prompt with explicit instructions for image analysis and error handling\n",
    "    prompt_text = f\"\"\"\n",
    "    Analyze the human face in this image.\n",
    "    1. Determine if there is exactly one clear, straight-facing human face visible. If not, state \"skipped_multiple_faces\" if multiple faces, or \"skipped_no_clear_face\" if no clear straight face is visible. In these skipped cases, return 'unknown' for all attribute values.\n",
    "    2. If a clear, straight-facing face is visible, infer the following attributes based *only* on the image:\n",
    "        - Face Shape (choose from: {', '.join(PREDEFINED_CATEGORIES['llm_thumbnail_face_shape'][:-1])})\n",
    "        - Skin Color (choose from: {', '.join(PREDEFINED_CATEGORIES['llm_thumbnail_skin_color'][:-1])})\n",
    "        - Eye Shape (choose from: {', '.join(PREDEFINED_CATEGORIES['llm_thumbnail_eye_shape'][:-1])})\n",
    "        - Lip Shape (choose from: {', '.join(PREDEFINED_CATEGORIES['llm_thumbnail_lip_shape'][:-1])})\n",
    "    3. For any attribute that cannot be confidently determined even if a clear face is present, state 'unknown'.\n",
    "    4. Return the result as a JSON object with keys: 'face_shape', 'skin_color', 'eye_shape', 'lip_shape', and 'status'.\n",
    "    Example: {{ \"face_shape\": \"Oval\", \"skin_color\": \"Medium\", \"eye_shape\": \"Almond\", \"lip_shape\": \"Fuller\", \"status\": \"analyzed\" }}\n",
    "    Example (skipped): {{ \"face_shape\": \"unknown\", \"skin_color\": \"unknown\", \"eye_shape\": \"unknown\", \"lip_shape\": \"unknown\", \"status\": \"skipped_multiple_faces\" }}\n",
    "    \"\"\"\n",
    "\n",
    "    image_parts = {\n",
    "        \"mimeType\": \"image/jpeg\", # Assuming JPEG output from get_image_as_base64\n",
    "        \"data\": image_base64\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = model.generate_content([prompt_text, image_parts])\n",
    "        # print(f\"Gemini raw response: {response.text}\") # For debugging\n",
    "\n",
    "        # Parse the JSON response\n",
    "        if response and response.text:\n",
    "            json_response = json.loads(response.text.strip())\n",
    "            response_data[\"llm_thumbnail_face_shape\"] = json_response.get(\"face_shape\", \"unknown\")\n",
    "            response_data[\"llm_thumbnail_skin_color\"] = json_response.get(\"skin_color\", \"unknown\")\n",
    "            response_data[\"llm_thumbnail_eye_shape\"] = json_response.get(\"eye_shape\", \"unknown\")\n",
    "            response_data[\"llm_thumbnail_lip_shape\"] = json_response.get(\"lip_shape\", \"unknown\")\n",
    "            response_data[\"llm_thumbnail_status\"] = json_response.get(\"status\", \"unknown\")\n",
    "\n",
    "            # Validate against predefined categories (optional, LLM should adhere with good prompt)\n",
    "            if response_data[\"llm_thumbnail_face_shape\"] not in PREDEFINED_CATEGORIES['llm_thumbnail_face_shape']:\n",
    "                response_data[\"llm_thumbnail_face_shape\"] = \"unknown\"\n",
    "            if response_data[\"llm_thumbnail_skin_color\"] not in PREDEFINED_CATEGORIES['llm_thumbnail_skin_color']:\n",
    "                response_data[\"llm_thumbnail_skin_color\"] = \"unknown\"\n",
    "            if response_data[\"llm_thumbnail_eye_shape\"] not in PREDEFINED_CATEGORIES['llm_thumbnail_eye_shape']:\n",
    "                response_data[\"llm_thumbnail_eye_shape\"] = \"unknown\"\n",
    "            if response_data[\"llm_thumbnail_lip_shape\"] not in PREDEFINED_CATEGORIES['llm_thumbnail_lip_shape']:\n",
    "                response_data[\"llm_thumbnail_lip_shape\"] = \"unknown\"\n",
    "            if response_data[\"llm_thumbnail_status\"] not in PREDEFINED_CATEGORIES['llm_thumbnail_status']:\n",
    "                response_data[\"llm_thumbnail_status\"] = \"error_llm_response\" # If status itself is invalid\n",
    "\n",
    "            if response_data[\"llm_thumbnail_status\"] == \"analyzed\" and \\\n",
    "               \"unknown\" in [response_data[\"llm_thumbnail_face_shape\"],\n",
    "                             response_data[\"llm_thumbnail_skin_color\"],\n",
    "                             response_data[\"llm_thumbnail_eye_shape\"],\n",
    "                             response_data[\"llm_thumbnail_lip_shape\"]]:\n",
    "                # If it said \"analyzed\" but returned unknown for all/most attributes,\n",
    "                # it's likely not a good analysis. Revert status if necessary.\n",
    "                # This is a heuristic.\n",
    "                pass # Can add more sophisticated checks here if needed\n",
    "\n",
    "        else:\n",
    "            response_data[\"llm_thumbnail_status\"] = \"error_llm_response\"\n",
    "\n",
    "    except (json.JSONDecodeError, AttributeError) as e:\n",
    "        print(f\"Error parsing Gemini response for thumbnail: {e}. Raw text: {response.text if response else 'No response text'}\")\n",
    "        response_data[\"llm_thumbnail_status\"] = \"error_llm_response\"\n",
    "    except Exception as e:\n",
    "        print(f\"Gemini thumbnail analysis failed: {e}\")\n",
    "        response_data[\"llm_thumbnail_status\"] = \"error_llm_response\"\n",
    "\n",
    "    return response_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "kY0LbMdeReVX"
   },
   "outputs": [],
   "source": [
    "def get_video_transcripts(video_id):\n",
    "    \"\"\"Fetches transcripts for a given video ID.\"\"\"\n",
    "    try:\n",
    "        transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)\n",
    "        # Prioritize manually created transcripts, then auto-generated English\n",
    "        transcript = None\n",
    "        for t in transcript_list:\n",
    "            if t.is_generated == False and t.language_code == 'en':\n",
    "                transcript = t\n",
    "                break\n",
    "        if not transcript: # If no manual English, try auto-generated English\n",
    "            for t in transcript_list:\n",
    "                if t.is_generated == True and t.language_code == 'en':\n",
    "                    transcript = t\n",
    "                    break\n",
    "        if not transcript: # If still no English, take first available\n",
    "            transcript = transcript_list[0]\n",
    "\n",
    "        full_transcript = \" \".join([item['text'] for item in transcript.fetch()])\n",
    "        return full_transcript\n",
    "    except TranscriptsDisabled:\n",
    "        # print(f\"Transcripts disabled for video {video_id}\")\n",
    "        return None\n",
    "    except NoTranscriptFound:\n",
    "        # print(f\"No transcript found for video {video_id}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        # print(f\"Error fetching transcript for video {video_id}: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- Gemini AI Function (retained from previous version) ---\n",
    "def analyze_content_with_gemini(channel_description, video_transcripts_sample):\n",
    "    \"\"\"\n",
    "    Analyzes channel content (description + sample transcripts) with Gemini AI\n",
    "    to infer content-related attributes using predefined categories.\n",
    "    Returns a dictionary of inferred attributes.\n",
    "    \"\"\"\n",
    "    model = genai.GenerativeModel(GEMINI_TEXT_MODEL)\n",
    "    combined_text = f\"Channel Description: {channel_description}\\n\\nRecent Video Content:\\n{video_transcripts_sample}\"\n",
    "\n",
    "    # Basic truncation if combined_text is too long for prompt (safety)\n",
    "    max_text_length = 200000 # Roughly 100k tokens to be safe\n",
    "    if len(combined_text) > max_text_length:\n",
    "        combined_text = combined_text[:max_text_length] + \" [...truncated for length...]\"\n",
    "\n",
    "    prompt_text = f\"\"\"\n",
    "    Analyze the following text content from a YouTube channel (description and recent video transcripts).\n",
    "    Infer the channel's primary focus based on the categories provided. Select ALL applicable tags for each category.\n",
    "    If a category is not applicable or cannot be confidently determined, return an empty array for that category.\n",
    "\n",
    "    Predefined Categories:\n",
    "    - features_aligned_with (choose from: {', '.join(PREDEFINED_CATEGORIES['face_shape'] + PREDEFINED_CATEGORIES['eye_shape'] + PREDEFINED_CATEGORIES['skin_undertone'] + PREDEFINED_CATEGORIES['skin_type_concerns'] + PREDEFINED_CATEGORIES['lip_shape'] + PREDEFINED_CATEGORIES['other_features'])})\n",
    "    - primary_makeup_style (choose from: {', '.join(PREDEFINED_CATEGORIES['primary_makeup_style'])})\n",
    "    - target_skill_level (choose from: {', '.join(PREDEFINED_CATEGORIES['target_skill_level'])})\n",
    "    - demographic_focus (choose from: {', '.join(PREDEFINED_CATEGORIES['demographic_focus'])})\n",
    "\n",
    "    Return the result as a JSON object. Ensure all keys from the predefined categories list are present, even if their value is an empty array.\n",
    "    Example: {{\n",
    "      \"features_aligned_with\": [\"round_face\", \"oily_skin\"],\n",
    "      \"primary_makeup_style\": [\"glam\"],\n",
    "      \"target_skill_level\": [\"beginner\"],\n",
    "      \"demographic_focus\": []\n",
    "    }}\n",
    "\n",
    "    Text Content:\n",
    "    {combined_text}\n",
    "    \"\"\"\n",
    "\n",
    "    content_attributes = {\n",
    "        \"features_aligned_with\": [],\n",
    "        \"primary_makeup_style\": [],\n",
    "        \"target_skill_level\": [],\n",
    "        \"demographic_focus\": []\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = model.generate_content(prompt_text)\n",
    "        # print(f\"Raw LLM Response: {response.text}\") # Uncomment for raw LLM output debugging\n",
    "\n",
    "        if response and response.text:\n",
    "            # --- DEBUG FIX: Strip Markdown code block if present ---\n",
    "            clean_text = response.text.strip()\n",
    "            if clean_text.startswith('```json') and clean_text.endswith('```'):\n",
    "                clean_text = clean_text[len('```json'):-len('```')].strip()\n",
    "\n",
    "            json_response = json.loads(clean_text)\n",
    "\n",
    "            # Extract and validate categories.\n",
    "            for key in content_attributes.keys():\n",
    "                extracted_tags = json_response.get(key, [])\n",
    "                if not isinstance(extracted_tags, list):\n",
    "                    extracted_tags = [] # Ensure it's a list\n",
    "\n",
    "                valid_tags = []\n",
    "                # Compile allowed tags for validation\n",
    "                allowed_tags = []\n",
    "                if key == \"features_aligned_with\":\n",
    "                    allowed_tags = (PREDEFINED_CATEGORIES['face_shape'] + PREDEFINED_CATEGORIES['eye_shape'] +\n",
    "                                    PREDEFINED_CATEGORIES['skin_undertone'] + PREDEFINED_CATEGORIES['skin_type_concerns'] +\n",
    "                                    PREDEFINED_CATEGORIES['lip_shape'] + PREDEFINED_CATEGORIES['other_features'])\n",
    "                else:\n",
    "                    allowed_tags = PREDEFINED_CATEGORIES.get(key, [])\n",
    "\n",
    "                for tag in extracted_tags:\n",
    "                    if tag in allowed_tags:\n",
    "                        valid_tags.append(tag)\n",
    "\n",
    "                content_attributes[key] = valid_tags\n",
    "\n",
    "    except (json.JSONDecodeError, AttributeError) as e:\n",
    "        print(f\"Error parsing Gemini response: {e}. Raw text: {response.text if response else 'No response text'}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Gemini content analysis failed: {e}\")\n",
    "\n",
    "    return content_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "wNySvWhNLGD4"
   },
   "outputs": [],
   "source": [
    "# --- Main Logic ---\n",
    "def run_channel_ingestion():\n",
    "    create_channels_table()\n",
    "    youtube = get_youtube_service()\n",
    "\n",
    "    all_channels_data = {} # Use a dictionary to avoid duplicates from different search queries\n",
    "    processed_channel_ids = set() # Keep track of IDs already processed for Gemini analysis\n",
    "\n",
    "    shuffled_queries = random.sample(SEARCH_QUERIES, len(SEARCH_QUERIES)) # Shuffle queries\n",
    "\n",
    "    for query in shuffled_queries:\n",
    "        print(f\"\\nSearching for channels with query: '{query}'...\")\n",
    "        # Get more results per query to increase chances of finding US channels\n",
    "        found_channels_for_query = search_youtube_channels(youtube, query, max_results=50)\n",
    "        print(\"found_channels_for_query\", found_channels_for_query)\n",
    "        # Filter for 'US' country and collect unique channel IDs for batch details\n",
    "        us_channel_ids_for_batch = []\n",
    "        for channel in found_channels_for_query:\n",
    "            if (channel.get('country') == 'US' or channel.get('country') is None) and channel['channel_id'] not in all_channels_data:\n",
    "                all_channels_data[channel['channel_id']] = {\n",
    "                    'channel_id': channel['channel_id'],\n",
    "                    'channel_name': channel['channel_name'],\n",
    "                    'channel_url': f\"https://www.youtube.com/channel/{channel['channel_id']}\",\n",
    "                    'channel_description': channel['channel_description'],\n",
    "                    'published_at': channel['published_at'],\n",
    "                    'profile_picture_url': channel['profile_picture_url'],\n",
    "                    'country': channel['country'],\n",
    "                    'default_language': channel['default_language'], # Initialize new field\n",
    "                    'keywords': json.dumps([]), # Initialize new field, will be populated later\n",
    "                    # Initialize other fields to default/None\n",
    "                    'subscriber_count': 0,\n",
    "                    'video_count': 0,\n",
    "                    'total_view_count': 0,\n",
    "                    'topic_ids': json.dumps([]),\n",
    "                    'last_content_upload_at': None,\n",
    "                    'last_updated': datetime.now(timezone.utc).isoformat(),\n",
    "                    'features_aligned_with': json.dumps([]),\n",
    "                    'primary_makeup_style': json.dumps([]),\n",
    "                    'target_skill_level': json.dumps([]),\n",
    "                    'demographic_focus': json.dumps([]),\n",
    "                    'llm_thumbnail_face_shape': \"unknown\",\n",
    "                    'llm_thumbnail_skin_color': \"unknown\",\n",
    "                    'llm_thumbnail_eye_shape': \"unknown\",\n",
    "                    'llm_thumbnail_lip_shape': \"unknown\",\n",
    "                    'llm_thumbnail_status': \"pending\",\n",
    "                    'llm_thumbnail_analysis_date': None\n",
    "                }\n",
    "                us_channel_ids_for_batch.append(channel['channel_id'])\n",
    "\n",
    "        print(f\"Found {len(us_channel_ids_for_batch)} new US channels from query '{query}'.\")\n",
    "\n",
    "        # Batch fetch statistics, topics, and uploads playlist IDs for new US channels\n",
    "        if us_channel_ids_for_batch:\n",
    "            print(f\"Fetching statistics, topic details, and branding settings for {len(us_channel_ids_for_batch)} channels...\")\n",
    "            batch_details = get_channel_statistics_and_topics(youtube, us_channel_ids_for_batch)\n",
    "            for channel_id, details in batch_details.items():\n",
    "                if channel_id in all_channels_data:\n",
    "                    all_channels_data[channel_id].update({\n",
    "                        'subscriber_count': details['subscriber_count'],\n",
    "                        'video_count': details['video_count'],\n",
    "                        'total_view_count': details['total_view_count'],\n",
    "                        'topic_ids': json.dumps(details['topic_ids']), # Store as JSON string\n",
    "                        'keywords': json.dumps(details['keywords'].split(',')) if isinstance(details['keywords'], str) else json.dumps(details['keywords']) # Store as JSON array, handle comma-separated string if needed\n",
    "                    })\n",
    "                    # Get last content upload timestamp\n",
    "                    last_upload = get_last_video_upload_timestamp(youtube, details['uploads_playlist_id'])\n",
    "                    all_channels_data[channel_id]['last_content_upload_at'] = last_upload\n",
    "            time.sleep(0.1) # Small delay to respect API limits\n",
    "\n",
    "    print(f\"\\n--- Total unique US channels found: {len(all_channels_data)} ---\")\n",
    "\n",
    "    # Process each unique US channel with Gemini AI\n",
    "    channels_to_process = list(all_channels_data.values())\n",
    "    random.shuffle(channels_to_process) # Shuffle again for processing order\n",
    "\n",
    "    for i, channel in enumerate(channels_to_process):\n",
    "        channel_id = channel['channel_id']\n",
    "        channel_name = channel['channel_name']\n",
    "\n",
    "        if channel_id in processed_channel_ids:\n",
    "            continue # Skip if already fully processed in a previous iteration\n",
    "\n",
    "        print(f\"\\nProcessing channel {i+1}/{len(channels_to_process)}: '{channel_name}' ({channel_id})\")\n",
    "\n",
    "        # --- Gemini Thumbnail Analysis ---\n",
    "        thumbnail_url = channel['profile_picture_url']\n",
    "        image_base64 = get_image_as_base64(thumbnail_url)\n",
    "        if image_base64:\n",
    "            thumbnail_llm_attrs = analyze_thumbnail_with_gemini(image_base64)\n",
    "            channel['llm_thumbnail_face_shape'] = thumbnail_llm_attrs['llm_thumbnail_face_shape']\n",
    "            channel['llm_thumbnail_skin_color'] = thumbnail_llm_attrs['llm_thumbnail_skin_color']\n",
    "            channel['llm_thumbnail_eye_shape'] = thumbnail_llm_attrs['llm_thumbnail_eye_shape']\n",
    "            channel['llm_thumbnail_lip_shape'] = thumbnail_llm_attrs['llm_thumbnail_lip_shape']\n",
    "            channel['llm_thumbnail_status'] = thumbnail_llm_attrs['llm_thumbnail_status']\n",
    "            channel['llm_thumbnail_analysis_date'] = datetime.now(timezone.utc).isoformat()\n",
    "            time.sleep(1) # Small delay for Gemini Vision API\n",
    "\n",
    "        # --- Gemini Content (Transcript) Analysis ---\n",
    "        # Get some recent video IDs for transcript analysis\n",
    "        video_ids_for_transcripts = []\n",
    "        try:\n",
    "            # Fetch most recent videos for this channel's uploads playlist\n",
    "            # Assuming all_channels_data[channel_id]['uploads_playlist_id'] was populated earlier\n",
    "            uploads_playlist_id = all_channels_data[channel_id].get('uploads_playlist_id')\n",
    "            if uploads_playlist_id:\n",
    "                playlist_items_response = youtube.playlistItems().list(\n",
    "                    part='snippet',\n",
    "                    playlistId=uploads_playlist_id,\n",
    "                    maxResults=5, # Get up to 5 most recent videos for content analysis\n",
    "                    fields='items/snippet/resourceId/videoId'\n",
    "                ).execute()\n",
    "                video_ids_for_transcripts = [\n",
    "                    item['snippet']['resourceId']['videoId']\n",
    "                    for item in playlist_items_response.get('items', [])\n",
    "                ]\n",
    "        except Exception as e:\n",
    "            print(f\"Could not fetch recent video IDs for channel {channel_id}: {e}\")\n",
    "\n",
    "        transcripts_sample_text = []\n",
    "        for vid_id in video_ids_for_transcripts:\n",
    "            transcript = get_video_transcripts(vid_id)\n",
    "            if transcript:\n",
    "                transcripts_sample_text.append(transcript)\n",
    "            time.sleep(0.5) # Delay between transcript fetches\n",
    "\n",
    "        combined_content_for_llm = channel['channel_description'] + \"\\n\\n\" + \"\\n\\n\".join(transcripts_sample_text)\n",
    "\n",
    "        if combined_content_for_llm.strip(): # Only analyze if there's actual content\n",
    "            content_llm_attrs = analyze_content_with_gemini(\n",
    "                channel['channel_description'], \"\\n\\n\".join(transcripts_sample_text)\n",
    "            )\n",
    "            channel['features_aligned_with'] = json.dumps(content_llm_attrs['features_aligned_with'])\n",
    "            channel['primary_makeup_style'] = json.dumps(content_llm_attrs['primary_makeup_style'])\n",
    "            channel['target_skill_level'] = json.dumps(content_llm_attrs['target_skill_level'])\n",
    "            channel['demographic_focus'] = json.dumps(content_llm_attrs['demographic_focus'])\n",
    "            time.sleep(1) # Small delay for Gemini Text API\n",
    "        else:\n",
    "            print(f\"No sufficient content (description/transcripts) for LLM analysis for channel {channel_id}.\")\n",
    "\n",
    "        # Update last_updated timestamp before inserting/updating\n",
    "        channel['last_updated'] = datetime.now(timezone.utc).isoformat()\n",
    "\n",
    "        # Insert/update into DB\n",
    "        insert_channel_data(channel)\n",
    "        processed_channel_ids.add(channel_id) # Mark as fully processed\n",
    "\n",
    "        time.sleep(0.2) # Small delay between channel processing for overall API limits\n",
    "\n",
    "    print(\"\\n--- Channel data ingestion complete! ---\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O7l1Jw0fRjHo",
    "outputId": "55ced74a-a7d7-4212-e76a-137d00138a4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'channels' created successfully in beauty_blueprint.db or already exists.\n",
      "\n",
      "Searching for channels with query: 'makeup artist'...\n",
      "channel_id : UCDLSt_KFcxWP-hsqAMuh0vg\n",
      "channel_id : UCz1HJ03TVULAEgYm8UgSHKg\n",
      "channel_id : UCru67MQuuq-hbbidUXT6CYA\n",
      "channel_id : UC_WmI554ltRf2hwzTqhWy4Q\n",
      "channel_id : UColpMuiLe9_vtmZPHFK-WvQ\n",
      "channel_id : UCQhBchX4GuCRr9OUc-arXVw\n",
      "channel_id : UCEcT5Ttsnl3kBMqyHmojobQ\n",
      "channel_id : UCCydBRF6RjrT58FV6KO-wwg\n",
      "channel_id : UCcFoijpjsNhVMQS33X5_kJA\n",
      "channel_id : UCHZBvhmGhnpJF4Q3YZGPz8g\n",
      "channel_id : UCp-hC1SfCbGjzbdY7A9ptFA\n",
      "channel_id : UCwUG82Z94P_kuiq0e5pSxBg\n",
      "channel_id : UCh57xkB9URnPOOCZifWG0Lw\n",
      "channel_id : UCFjCz-eA1FsQG77i9tJ--vg\n",
      "channel_id : UCRi278WPXTFmmcf8taOg_vA\n",
      "channel_id : UCwLk1tcZV1UGWOcwup7Wn7g\n",
      "channel_id : UCs2dbihiQTm6gJHBo-fE2Xw\n",
      "channel_id : UCHQO9xPSROEHYHUk_T82l6w\n",
      "channel_id : UCe39X6QuOsZl8irjfe_1c8A\n",
      "channel_id : UCMXav6XYQsteXkeblvLKMVw\n",
      "channel_id : UCaUqvfjmwcGepG9nCOcS9zw\n",
      "channel_id : UC2GUcyD6KYjmU_ofQtPTSSA\n",
      "channel_id : UCmcN9KeZhK2TmeRQdz2EDPQ\n",
      "channel_id : UCo3fUW2rnvrTSyIFJZsetUg\n",
      "channel_id : UChJ1gs4RpGySr8qCVRNYgxg\n",
      "channel_id : UCfDbxlVnpzk9LkhuScTiTuw\n",
      "channel_id : UCsHKvqyI9wLkaZiQAiA3rtw\n",
      "channel_id : UCdP-53KeqzoVuZauXG7QDbw\n",
      "channel_id : UCWqGMa4mq4kGthqpoR6F57g\n",
      "channel_id : UCNsa-wvOa-hegXO1GBa692w\n",
      "channel_id : UC3KP6dvAauZp5ilgg3GS8RQ\n",
      "channel_id : UC4K6dQInBoTG3lWv7ySqhZA\n",
      "channel_id : UCCvoAe__WFYMNAEN-C-CtYA\n",
      "channel_id : UCjwERJDotcRLaXakJADlCXw\n",
      "channel_id : UC8UtwF8BLoEimC8pSrU2_hA\n",
      "channel_id : UCuNKF_jUWmbgnSCOqW3RFXg\n",
      "channel_id : UCaQRKpLY--5iPaZuat6EJ_w\n",
      "channel_id : UCj4vAUpuWryfCSebYy6gRFw\n",
      "channel_id : UC7h9Hhv4Unc2lUMCIpMKG-A\n",
      "channel_id : UCk_Fes1FHP_x7omhO7DmnPQ\n",
      "channel_id : UCK8P_pm9YPyQZybnWDMyZRA\n",
      "channel_id : UCif5BkqPLF4eFstYeOGeNUQ\n",
      "channel_id : UCHXWTLYx6W_-SNKbfF3QkGA\n",
      "channel_id : UCCHGyjfySFfwErChFw7eRdw\n",
      "channel_id : UCn84tkreBkUQS50GUAAV-ig\n",
      "channel_id : UCof1sfffY6oi1ykV76jvpGw\n",
      "channel_id : UCd-xyUQE8HlyKgZ1UrD0Q8Q\n",
      "channel_id : UCXfGWFGNoJrKCaKN88gtfdg\n",
      "channel_id : UCl9eTaJHvf3U7eXPa7YKkTQ\n",
      "channel_id : UCpc2Jn8DTyNyOzriUK4abww\n",
      "found_channels_for_query [{'channel_id': 'UCDLSt_KFcxWP-hsqAMuh0vg', 'channel_name': 'Judy D', 'channel_description': '', 'published_at': '2016-08-28T00:03:20Z', 'profile_picture_url': 'https://yt3.ggpht.com/ytc/AIdro_mtAkciQb7FAIUqtfIPQNABClDIEtBvX3tPPfBY35NNyp0=s800-c-k-c0xffffffff-no-rj-mo', 'default_language': None, 'country': None, 'uploads_playlist_id': None}, {'channel_id': 'UCz1HJ03TVULAEgYm8UgSHKg', 'channel_name': '  Makeup Artist ', 'channel_description': 'Hello my friends, welcome to the world of makeup and beauty.', 'published_at': '2022-11-16T04:52:23Z', 'profile_picture_url': 'https://yt3.ggpht.com/wGfdAXokAq_LSgj47w_4Te_7kaui0HZFLlDCJTbUv-yl_zUJg6vQcBxiFksbatNWR_pEc4XvJw=s800-c-k-c0xffffffff-no-rj-mo', 'default_language': None, 'country': None, 'uploads_playlist_id': None}, {'channel_id': 'UCru67MQuuq-hbbidUXT6CYA', 'channel_name': 'Shahlabacker Makeup Artist', 'channel_description': 'I am shahlabacker, makeup artist from kerala , south India.By god grace am here in this field for last few years and done bridal ...', 'published_at': '2021-03-24T02:52:46Z', 'profile_picture_url': 'https://yt3.ggpht.com/yNwCLpMVyC46yB9EmqOgMdTyTfBudVenaaK1T7-Nj-ej3UnmfP_eWR73em_fhHEJ2lEpwVMQ=s800-c-k-c0xffffffff-no-rj-mo', 'default_language': None, 'country': None, 'uploads_playlist_id': None}, {'channel_id': 'UC_WmI554ltRf2hwzTqhWy4Q', 'channel_name': 'Karolina Zientek MakeUp Artist', 'channel_description': 'To moja wielka pasja... mój piękny, kolorowy świat.', 'published_at': '2013-09-23T17:38:36Z', 'profile_picture_url': 'https://yt3.ggpht.com/ytc/AIdro_n_XYf7osyYDg0qnF6a5ATMfQbRbnT08mcq6kUSLR5LCvo=s800-c-k-c0xffffffff-no-rj-mo', 'default_language': None, 'country': None, 'uploads_playlist_id': None}, {'channel_id': 'UColpMuiLe9_vtmZPHFK-WvQ', 'channel_name': 'Zoë ASMR makeup artist', 'channel_description': 'As a professional makeup artist ( not pretending this is me ) with a deep-rooted passion for makeup , beauty, skincare & wellbeing ...', 'published_at': '2018-05-08T22:51:04Z', 'profile_picture_url': 'https://yt3.ggpht.com/pItanV23nM19WBe6KkCKF2hrUKu_WrEqnjtMZQNoXs4A7ac6EuReZslIskidjuEt7i6WW7r1HpY=s800-c-k-c0xffffffff-no-rj-mo', 'default_language': None, 'country': None, 'uploads_playlist_id': None}, {'channel_id': 'UCQhBchX4GuCRr9OUc-arXVw', 'channel_name': 'Waad Makeup Artist', 'channel_description': '', 'published_at': '2016-06-07T22:06:46Z', 'profile_picture_url': 'https://yt3.ggpht.com/ytc/AIdro_mffWLKwo-rKVIcY33mV7TfTiHffl--SEImQ6SKyqlabA=s800-c-k-c0xffffffff-no-rj-mo', 'default_language': None, 'country': None, 'uploads_playlist_id': None}, {'channel_id': 'UCEcT5Ttsnl3kBMqyHmojobQ', 'channel_name': 'MAKEUP BY MARIO', 'channel_description': 'MAKEUP BY MARIO was founded by Master Makeup Artist Mario Dedivanovic. Inspired by decades of groundbreaking artistry, ...', 'published_at': '2020-09-28T20:55:06Z', 'profile_picture_url': 'https://yt3.ggpht.com/jva-Facbr_B1xFJu5vpnk3gm6JaaiP5SKBl1MeU05yBrzxYWmDtDSzidBai4M9MHTMvPmpPe6Q=s800-c-k-c0xffffffff-no-rj-mo', 'default_language': None, 'country': None, 'uploads_playlist_id': None}, {'channel_id': 'UCCydBRF6RjrT58FV6KO-wwg', 'channel_name': 'Makeup By Nikki La Rose', 'channel_description': \"Hi everyone! My name is Nikki! I'm a professional, celebrity & Editorial Makeup artist of 16 years. I'm so happy to now be sharing ...\", 'published_at': '2013-09-15T00:07:15Z', 'profile_picture_url': 'https://yt3.ggpht.com/oeQfpqyTCBbCfFpEODIMvuzLDJp1AlNhlPH_V5rqSR1ifO41LrCT7i0zvsm5h41nWrh3Bpai=s800-c-k-c0xffffffff-no-rj-mo', 'default_language': None, 'country': None, 'uploads_playlist_id': None}, {'channel_id': 'UCcFoijpjsNhVMQS33X5_kJA', 'channel_name': 'Vincent Ford', 'channel_description': 'Pro Makeup Artist & Beauty Guru Real talk on beauty trends, makeup, skincare and pro makeup artistry. Dive into my world of ...', 'published_at': '2011-01-23T21:17:49Z', 'profile_picture_url': 'https://yt3.ggpht.com/ytc/AIdro_nQi-KwRkz--bCnCP5daRGs4iZdHhUoWu6_wLpN-tC2AV0=s800-c-k-c0xffffffff-no-rj-mo', 'default_language': None, 'country': None, 'uploads_playlist_id': None}, {'channel_id': 'UCHZBvhmGhnpJF4Q3YZGPz8g', 'channel_name': 'MJ makeup artist 1234', 'channel_description': 'I am here to teach u important tips to be a beautician. If u want to order our products or to learn more contact us: 0323 0505612 or ...', 'published_at': '2017-01-27T19:34:47Z', 'profile_picture_url': 'https://yt3.ggpht.com/ytc/AIdro_k3MtNFT8NV1wCjiCbGrBHNy1nz9jWb4NsVIoXwHPnY=s800-c-k-c0xffffffff-no-rj-mo', 'default_language': None, 'country': None, 'uploads_playlist_id': None}, {'channel_id': 'UCp-hC1SfCbGjzbdY7A9ptFA', 'channel_name': 'MAKEUP ARTIST KUMARESH', 'channel_description': 'JK MAKEUP STUDIO & ACADEMY BY MAKEUP ARTIST KUMARESH STUDIO LOCATION- GURGAON- C601 DEW DROP ...', 'published_at': '2012-03-25T19:25:06Z', 'profile_picture_url': 'https://yt3.ggpht.com/InuSqF2MYqdLS8mw_47MoZexo0MPonLTlA2ctbo9bx0gY1IiTpesPaBEzOZXI_Zo5x-FGgdkpQ=s800-c-k-c0xffffffff-no-rj-mo', 'default_language': None, 'country': None, 'uploads_playlist_id': None}, {'channel_id': 'UCwUG82Z94P_kuiq0e5pSxBg', 'channel_name': 'Erica Taylor Beauty ', 'channel_description': 'Thanks for coming to my YouTube Channel. I have been a Make-up Artist & Cosmetic Trainer for 27+ years. I live in New York with ...', 'published_at': '2015-09-28T00:41:19Z', 'profile_picture_url': 'https://yt3.ggpht.com/A1pG2AnTD8RXbIlVsoDJCLdbIba5jL9ryaXLpZII6zC5gf-vQWyl7CNyNMUXyd2__A_j8rW28g=s800-c-k-c0xffffffff-no-rj-mo', 'default_language': None, 'country': None, 'uploads_playlist_id': None}, {'channel_id': 'UCh57xkB9URnPOOCZifWG0Lw', 'channel_name': 'Summer makeup artist', 'channel_description': \"Hi everyone I'm Summer and I'm professional makeup artist. My passion is makeup and make people feel beautiful. I am new on ...\", 'published_at': '2017-03-06T00:52:21Z', 'profile_picture_url': 'https://yt3.ggpht.com/ytc/AIdro_lmLDzrm4SrsA8PtlguPYYXKz2pbsvYc4HicMUUSEexfNw=s800-c-k-c0xffffffff-no-rj-mo', 'default_language': None, 'country': None, 'uploads_playlist_id': None}, {'channel_id': 'UCFjCz-eA1FsQG77i9tJ--vg', 'channel_name': 'Andrea Ruiz Salazar', 'channel_description': 'Going to the worst places for your pleasure…', 'published_at': '2016-10-19T15:00:57Z', 'profile_picture_url': 'https://yt3.ggpht.com/ytc/AIdro_nwMh0LG4lwE1QQqqZSXuyq6Gl3xV1Jp0VgzAKLfR7tlYE=s800-c-k-c0xffffffff-no-rj-mo', 'default_language': None, 'country': None, 'uploads_playlist_id': None}, {'channel_id': 'UCRi278WPXTFmmcf8taOg_vA', 'channel_name': 'monica sobhy makeup artist', 'channel_description': 'نورتيني ❤️ هنا هتلاقي فيديوهات متنوعة ( تتوريال لوكات مختلفة - ريفيوهات منتجات - وصفات طبيعية - كورس ميك اب - سكين كير ...', 'published_at': '2023-10-09T17:52:46Z', 'profile_picture_url': 'https://yt3.ggpht.com/nMnPnNEzeHpGO4Vo4CLz1XyysIiFsujbdOSgloEtBNIszzXrizFxLprjMIa-u8GQJJS2_4wzCA=s800-c-k-c0xffffffff-no-rj-mo', 'default_language': None, 'country': None, 'uploads_playlist_id': None}, {'channel_id': 'UCwLk1tcZV1UGWOcwup7Wn7g', 'channel_name': 'Maria the Makeup Artist ', 'channel_description': \"Welcome to My World of Beauty & Modesty Assalamu Alaikum! I'm a professional makeup artist who began her journey in 2020 ...\", 'published_at': '2018-02-09T16:11:58Z', 'profile_picture_url': 'https://yt3.ggpht.com/ioVv4phJUbsh4fV3ilwatNgVYTEtFW_mg_PPJkUBUvb5l3Vic88bNZVhNgs0eKE4SEI_7P2NVg=s800-c-k-c0xffffffff-no-rj-mo', 'default_language': None, 'country': None, 'uploads_playlist_id': None}, {'channel_id': 'UCs2dbihiQTm6gJHBo-fE2Xw', 'channel_name': 'The Makeup Artist Honey ', 'channel_description': 'Hey I am Honey I want your support I love makeup and I wanted to open a channel it was my dream and want support from you all ...', 'published_at': '2022-11-09T13:19:38Z', 'profile_picture_url': 'https://yt3.ggpht.com/rD43U6mlmrjZghSk7nPq8-ea0sl7tmp2ELC1gcD2xGzbSGvA_63jfzaDDH6UBDrooVy1MGb9Ow=s800-c-k-c0xffffffff-no-rj-mo', 'default_language': None, 'country': None, 'uploads_playlist_id': None}, {'channel_id': 'UCHQO9xPSROEHYHUk_T82l6w', 'channel_name': 'Quach Anh Makeup Artist', 'channel_description': 'Tất cả những gì liên quan đến làm đẹp của chị em phụ nữ dưới góc độ cá nhân ^^', 'published_at': '2013-09-04T04:21:11Z', 'profile_picture_url': 'https://yt3.ggpht.com/81z3W2OBBefDxnW7aN0CL0-mJeIXI2jiHwhQiBlYckwQQUN1A6EonbPKk5fErH_A6oaWZrkqs5A=s800-c-k-c0xffffffff-no-rj-mo', 'default_language': None, 'country': None, 'uploads_playlist_id': None}, {'channel_id': 'UCe39X6QuOsZl8irjfe_1c8A', 'channel_name': 'KhaRieZa MakeUp Artist', 'channel_description': 'WELCOME TO MY CHANNEL KhaRieZa MakeUp Artis   ( Siap Melayani ) MakeUp Pengantin MakeUp Karnaval Dan Wisuda ...', 'published_at': '2019-05-05T06:11:20Z', 'profile_picture_url': 'https://yt3.ggpht.com/Kz3DVgRE6aNHLzrMEHmpYn7cX_gZZVp_hY-jPSSLBJ1MBbM0JrK3rjcb_2hJbPvfFXq9DLGGXQ=s800-c-k-c0xffffffff-no-rj-mo', 'default_language': None, 'country': None, 'uploads_playlist_id': None}, {'channel_id': 'UCMXav6XYQsteXkeblvLKMVw', 'channel_name': 'Mai Phan Makeup Artist', 'channel_description': 'Makeup chưa bao giờ dễ dàng đến thế! Là một kênh chuyên về makeup và tư vấn makeup, Mai Phan Makeup Artist mong muốn ...', 'published_at': '2016-05-11T07:33:19Z', 'profile_picture_url': 'https://yt3.ggpht.com/ytc/AIdro_m2P0F6G3ZUio5WYlDUGfgAz2NuES-jxR_XJNjP0TKvmw=s800-c-k-c0xffffffff-no-rj-mo', 'default_language': None, 'country': None, 'uploads_playlist_id': None}, {'channel_id': 'UCaUqvfjmwcGepG9nCOcS9zw', 'channel_name': 'Seema the real makeup artist', 'channel_description': '', 'published_at': '2012-10-27T00:03:30Z', 'profile_picture_url': 'https://yt3.ggpht.com/LIxAsO0ijSUbv449Ock-kSo1kFhzFLK-bbtxbAmc_IIcWpnxLx7VMqwP5Kf23_KlsWwJy5GkYA=s800-c-k-c0xffffffff-no-rj-mo', 'default_language': None, 'country': None, 'uploads_playlist_id': None}, {'channel_id': 'UC2GUcyD6KYjmU_ofQtPTSSA', 'channel_name': 'Robert Welsh', 'channel_description': \"Hello! I'm Robert, A professional makeup artist and content creator. I created this channel to share my years of experience and ...\", 'published_at': '2015-05-21T09:05:47Z', 'profile_picture_url': 'https://yt3.ggpht.com/Isg224Hwrgg3518FXle_NnSILNYKnG0Qv_6TjqIKcjSVC87IrXNGNmoLztZkTqOv5yUPUPPo=s800-c-k-c0xffffffff-no-rj-mo', 'default_language': None, 'country': None, 'uploads_playlist_id': None}, {'channel_id': 'UCmcN9KeZhK2TmeRQdz2EDPQ', 'channel_name': 'House of The Makeup Artists', 'channel_description': '', 'published_at': '2022-09-03T08:15:57Z', 'profile_picture_url': 'https://yt3.ggpht.com/O4J_ZbLKlY6D3fdtKzE-B2ykNI4sIXWBuZELIA-ZIPFBZ_SKVofHlwT2xl-6VR2zNwLy033C_A=s800-c-k-c0xffffffff-no-rj-mo', 'default_language': None, 'country': None, 'uploads_playlist_id': None}, {'channel_id': 'UCo3fUW2rnvrTSyIFJZsetUg', 'channel_name': 'Vikas Vks Makeup artist', 'channel_description': \"Hello , I am Vikas Vks. I am a makeup artist from Kerala, India. By God's grace, I have been lucky to do makeup for great ...\", 'published_at': '2020-04-03T17:10:17Z', 'profile_picture_url': 'https://yt3.ggpht.com/YOI_-VDmpm2P74mjNgj674go1RCeFwpLVYBfvJ_xHbl-FFU_KNanRHotaZf-Y7SKsDWbxFDRLQ=s800-c-k-c0xffffffff-no-rj-mo', 'default_language': None, 'country': None, 'uploads_playlist_id': None}, {'channel_id': 'UChJ1gs4RpGySr8qCVRNYgxg', 'channel_name': 'Clarissa Makeup Artist', 'channel_description': 'Welcome to C l a r i s s a   M a k e - u p    A r t i s t  YouTube Channel! Facebook: Clarissa Make-up Artist Instagram: ...', 'published_at': '2016-02-17T11:17:12Z', 'profile_picture_url': 'https://yt3.ggpht.com/ytc/AIdro_kkbmJybJk6tvBh5voj8M-94e-M6npGiTDo39NTDhttLw=s800-c-k-c0xffffffff-no-rj-mo', 'default_language': None, 'country': None, 'uploads_playlist_id': None}, {'channel_id': 'UCfDbxlVnpzk9LkhuScTiTuw', 'channel_name': 'Shiny Makeup Artist ❤️', 'channel_description': 'My channel is all about Love, Makeup, Travel, Cooking & Cars  ❤️   Shiny Barbara Makeup Studio & Academy Follow my Insta ...', 'published_at': '2014-05-12T12:31:16Z', 'profile_picture_url': 'https://yt3.ggpht.com/T3Ar_MV-XmrgrP5_2b78GbxCSOy71Mj6Rm8kww7OITyWN6N800hEYxH08_f9FVKR1S_uaQ4233c=s800-c-k-c0xffffffff-no-rj-mo', 'default_language': None, 'country': None, 'uploads_playlist_id': None}, {'channel_id': 'UCsHKvqyI9wLkaZiQAiA3rtw', 'channel_name': 'Savitha Makeup Artist', 'channel_description': \"Hi, I'm Savitha Bhandary, a professional makeup artist sharing easy tutorials, glam transformations, pro tips, and product reviews.\", 'published_at': '2025-06-23T16:50:11Z', 'profile_picture_url': 'https://yt3.ggpht.com/tpXoquLQBpHmTGgJu-cOB80t9WE16a_5p5Yb4N-A2CIafFOCAQi8e9D9xHVr2nISm06vuStIcWA=s800-c-k-c0xffffffff-no-rj-mo', 'default_language': None, 'country': None, 'uploads_playlist_id': None}, {'channel_id': 'UCdP-53KeqzoVuZauXG7QDbw', 'channel_name': 'MAKEUP ARTIST HENA', 'channel_description': \"Every look by Makeup Artist Hena is crafted by understanding the client's skin type, texture and preference and creates a look that ...\", 'published_at': '2020-08-22T18:37:33Z', 'profile_picture_url': 'https://yt3.ggpht.com/sK4JxLYQr9c9HgVztjCIctFfxb3o8d39Y1fObYYL4tb3N-En6zS09LTjzeLy6z7C-IwfGtQOlg=s800-c-k-c0xffffffff-no-rj-mo', 'default_language': None, 'country': None, 'uploads_playlist_id': None}, {'channel_id': 'UCWqGMa4mq4kGthqpoR6F57g', 'channel_name': 'Prakruthi Rao Makeup Artist', 'channel_description': 'Hi beauties !! I am an Indian girl who make contents on beauty , fashion and lifestyle. I am a Fashion designer, Makeup artist and ...', 'published_at': '2017-11-19T09:27:20Z', 'profile_picture_url': 'https://yt3.ggpht.com/_VZeVLGGUf7QO9pKQhigZULp1Giteer3LfTcXCstCwSQq3gDHa9reg-IlKdA-oHij7UfBII0CQ=s800-c-k-c0xffffffff-no-rj-mo', 'default_language': None, 'country': None, 'uploads_playlist_id': None}, {'channel_id': 'UCNsa-wvOa-hegXO1GBa692w', 'channel_name': 'Parvathy Raj Makeup Artist', 'channel_description': 'Celebrity Makeup Artist.', 'published_at': '2019-10-22T10:43:27Z', 'profile_picture_url': 'https://yt3.ggpht.com/ytc/AIdro_nWacrMCZVVzFiPuxfdrE4FZHiYtDM7ajGu7NJ_7T6t6rM=s800-c-k-c0xffffffff-no-rj-mo', 'default_language': None, 'country': None, 'uploads_playlist_id': None}, {'channel_id': 'UC3KP6dvAauZp5ilgg3GS8RQ', 'channel_name': 'Reema Khan Makeup Artist', 'channel_description': 'Hey friends, I am Reema khan and thank you for letting me introduce my channel to you. I have created this channel to give you ...', 'published_at': '2017-08-05T08:50:00Z', 'profile_picture_url': 'https://yt3.ggpht.com/goAXpGMlJc_X3F_s88HWakwsEreRf6-P3GtPvL0jV3SUaQ_XqqHWhdOW8uwGVeLJj0eqPX4ASQ=s800-c-k-c0xffffffff-no-rj-mo', 'default_language': None, 'country': None, 'uploads_playlist_id': None}, {'channel_id': 'UC4K6dQInBoTG3lWv7ySqhZA', 'channel_name': 'Your Favourite Makeup Artist', 'channel_description': 'Here you can see your favorite Makeup Artist makeup video . Based in Gurgaon(New Delhi),India .who is none other than your ...', 'published_at': '2021-03-25T10:27:12Z', 'profile_picture_url': 'https://yt3.ggpht.com/UXf2jEH3-jTHYKHzisxjHdPq4I3s9SPzV1jB1P7ucw9_f7n43m3kP_WzxIJztYQCBFKu6rE5=s800-c-k-c0xffffffff-no-rj-mo', 'default_language': None, 'country': None, 'uploads_playlist_id': None}, {'channel_id': 'UCCvoAe__WFYMNAEN-C-CtYA', 'channel_name': 'Wayne Goss', 'channel_description': 'Business enquiries: gossmakeupartist@googlemail.com Love makeup? Want to improve your makeup skills? Interested in ...', 'published_at': '2008-08-05T11:08:05Z', 'profile_picture_url': 'https://yt3.ggpht.com/QTCUyrbFaQqfqubvNMdHF07fiSq1Qmf16Wv-tB7TCXzi7sHJoS9dRNO2H9giQ_yuqMb88gEJEQ=s800-c-k-c0xffffffff-no-rj-mo', 'default_language': None, 'country': None, 'uploads_playlist_id': None}, {'channel_id': 'UCjwERJDotcRLaXakJADlCXw', 'channel_name': 'Asmaa Adel makeup artist', 'channel_description': 'قناتى للمكياج وللتعرف على المنتجات الجديدة اول بأول بنقل تجربتى عن كل جديد مهنتى ميك اب ارتيست make up artist واعشق المكياج.', 'published_at': '2010-01-10T16:24:20Z', 'profile_picture_url': 'https://yt3.ggpht.com/ytc/AIdro_ldjavyKM3KgPcOCpLSZjagG7Ounw8QOcy0lHGD7CTBWVZo=s800-c-k-c0xffffffff-no-rj-mo', 'default_language': None, 'country': None, 'uploads_playlist_id': None}, {'channel_id': 'UC8UtwF8BLoEimC8pSrU2_hA', 'channel_name': 'Mayuri Sinha Sarkar - Makeup Artist', 'channel_description': '', 'published_at': '2018-04-26T15:22:22Z', 'profile_picture_url': 'https://yt3.ggpht.com/ytc/AIdro_nfYmts3mt8RMVzX0mOJecHxr489HdZwVH68n3gOsvY_w=s800-c-k-c0xffffffff-no-rj-mo', 'default_language': None, 'country': None, 'uploads_playlist_id': None}, {'channel_id': 'UCuNKF_jUWmbgnSCOqW3RFXg', 'channel_name': 'Karneet Kaur Makeup Artist', 'channel_description': 'VLOGER BLOGGER.', 'published_at': '2019-10-14T09:20:21Z', 'profile_picture_url': 'https://yt3.ggpht.com/BnE0onM2p0_vgc0Sh1x95nB_pxx2-E5ddluL75FvrQVcojg8QIC84q0YahwuFqRVrxzuHdNW=s800-c-k-c0xffffffff-no-rj-mo', 'default_language': None, 'country': None, 'uploads_playlist_id': None}, {'channel_id': 'UCaQRKpLY--5iPaZuat6EJ_w', 'channel_name': 'Aarushi Oswal Makeup Artist', 'channel_description': 'Professional makeup artist trained in New York based in Ludhiana. With 16+ years of experience & 7+ certifications.', 'published_at': '2010-08-31T04:28:34Z', 'profile_picture_url': 'https://yt3.ggpht.com/9PXgV83QlZMFNPny0X7BsmAAqwIvd6g0cA7aB3bxAcgl-bwaV1IGL_wubhlf7kKzRcwU0wlA75E=s800-c-k-c0xffffffff-no-rj-mo', 'default_language': None, 'country': None, 'uploads_playlist_id': None}, {'channel_id': 'UCj4vAUpuWryfCSebYy6gRFw', 'channel_name': 'Tania Makeup Artist', 'channel_description': \"I love nothing more than making someone feel beautiful. Throughout the year, I've met many people and worked on many faces to ...\", 'published_at': '2014-01-17T08:01:46Z', 'profile_picture_url': 'https://yt3.ggpht.com/ytc/AIdro_nWFmB8xcPNwStPjkIqLdNqd0a4Qia6oYEGiOqoI5a2Y8Q=s800-c-k-c0xffffffff-no-rj-mo', 'default_language': None, 'country': None, 'uploads_playlist_id': None}, {'channel_id': 'UC7h9Hhv4Unc2lUMCIpMKG-A', 'channel_name': 'Mukul Richards Makeup Artist', 'channel_description': 'Product revies, tutorials, hyperpigmentation, brown skin friendly makeup tips.', 'published_at': '2015-07-03T06:59:44Z', 'profile_picture_url': 'https://yt3.ggpht.com/95JlO8U5G5QrH44JxFLkeV9n96sOkqjZSvD59ApaydUJT7KspNB4jqruCF4qTyCkdkxu2PdhyN0=s800-c-k-c0xffffffff-no-rj-mo', 'default_language': None, 'country': None, 'uploads_playlist_id': None}, {'channel_id': 'UCk_Fes1FHP_x7omhO7DmnPQ', 'channel_name': 'Tony The Makeup Artist', 'channel_description': 'Tony Michael here, A Well known Celebrity Makeup Artist and Beauty Blogger from Kochi, Kerala... Expert in all types of Makeups, ...', 'published_at': '2010-07-29T06:00:22Z', 'profile_picture_url': 'https://yt3.ggpht.com/cHcdDx9WP0Ay2u-hWRsECEN5dGXwDr7cbFVQB54Gz-w1_2R2z9-nDaXG-tJtFFxpTRHKZ9duyg=s800-c-k-c0xffffffff-no-rj-mo', 'default_language': None, 'country': None, 'uploads_playlist_id': None}, {'channel_id': 'UCK8P_pm9YPyQZybnWDMyZRA', 'channel_name': 'Saim Makeup artist', 'channel_description': '', 'published_at': '2017-10-13T07:31:07Z', 'profile_picture_url': 'https://yt3.ggpht.com/ytc/AIdro_lm0n9VjFyv1ABvj3Sf6uodxGzMidWtFoK0I1ii3Kl_Jw0=s800-c-k-c0xffffffff-no-rj-mo', 'default_language': None, 'country': None, 'uploads_playlist_id': None}, {'channel_id': 'UCif5BkqPLF4eFstYeOGeNUQ', 'channel_name': 'Kavya makeupartist ', 'channel_description': \"Instagram I'd = Kavya__makeupartist Contact number =7736274794 I am a freelance makeup artist from kochi, kerala, india. our ...\", 'published_at': '2022-03-11T16:36:49Z', 'profile_picture_url': 'https://yt3.ggpht.com/y0WRHL-0qIXdRpSUCzaanrc5EzTDuH1i6LTEbrj5xmGzNZi8U7L_ZgEr86Byu8m_ihAs3ikU=s800-c-k-c0xffffffff-no-rj-mo', 'default_language': None, 'country': None, 'uploads_playlist_id': None}, {'channel_id': 'UCHXWTLYx6W_-SNKbfF3QkGA', 'channel_name': 'Sadia Makeup Artist', 'channel_description': '', 'published_at': '2021-03-03T08:51:59Z', 'profile_picture_url': 'https://yt3.ggpht.com/0gS47ZSqcH9lU7mbpyyv1SuqwYEkJXTye8EOtkQ8faJ9ajir0pqwRxRDhSyNjG-JwayzMqO53w=s800-c-k-c0xffffffff-no-rj-mo', 'default_language': None, 'country': None, 'uploads_playlist_id': None}, {'channel_id': 'UCCHGyjfySFfwErChFw7eRdw', 'channel_name': 'Paohilda makeup artist', 'channel_description': 'MUA yang bantu kamu jago makeup ✨ Find me on ig and tt @paohilda.', 'published_at': '2022-12-10T07:45:09Z', 'profile_picture_url': 'https://yt3.ggpht.com/dBrtVHMdgbzAGPvlxm24LLqdse4h13E5PYhoIjyfFoBb86R_vzECK3yHhuyagnDnh55L2tmDNA=s800-c-k-c0xffffffff-no-rj-mo', 'default_language': None, 'country': None, 'uploads_playlist_id': None}, {'channel_id': 'UCn84tkreBkUQS50GUAAV-ig', 'channel_name': 'Makeup Artist Payel Sinha Halder', 'channel_description': 'Promotion/Collaboration payelsinhaofficial8991@gmail.com.', 'published_at': '2023-07-15T17:23:05Z', 'profile_picture_url': 'https://yt3.ggpht.com/ARu6yg8w_1EnYbTK_SQLmq9gYhC3o6pUO8q9TfySy-7VrdMhRYq4iL9kZ3KnQ7zgXoAMFuKj=s800-c-k-c0xffffffff-no-rj-mo', 'default_language': None, 'country': None, 'uploads_playlist_id': None}, {'channel_id': 'UCof1sfffY6oi1ykV76jvpGw', 'channel_name': 'Saanjh Makeup Artist', 'channel_description': \"Welcome to my YouTube channel 'Saanjh Makeup Artist'. My Channel is all about Makeup, Beauty Tips, nails, Hairstyles and ...\", 'published_at': '2022-06-03T04:33:17Z', 'profile_picture_url': 'https://yt3.ggpht.com/Z80lFe7LSlo0iN8bK9ln_Y9GKFAmWFzm0RgJqq6Ww7CXq67eVcSo7znRBzel1Bv8iHD6KgTMNQ=s800-c-k-c0xffffffff-no-rj-mo', 'default_language': None, 'country': None, 'uploads_playlist_id': None}, {'channel_id': 'UCd-xyUQE8HlyKgZ1UrD0Q8Q', 'channel_name': 'Aliza Makeup artist', 'channel_description': \"Welcome to my channel! ✨ I'm Aliza, a passionate makeup artist based in Mumbai. Join me on a journey of beauty, creativity, ...\", 'published_at': '2020-09-10T17:22:55Z', 'profile_picture_url': 'https://yt3.ggpht.com/Oc05sEJZ1mQlaKgqmm-JNIZQCz0kTnzqt9tlogRmbXnfsaB6cbupJ88N5WrYE9J7ALl7EDDn2g=s800-c-k-c0xffffffff-no-rj-mo', 'default_language': None, 'country': None, 'uploads_playlist_id': None}, {'channel_id': 'UCXfGWFGNoJrKCaKN88gtfdg', 'channel_name': 'Kanya Makeup Artist Tuticorin', 'channel_description': '', 'published_at': '2013-05-04T18:05:29Z', 'profile_picture_url': 'https://yt3.ggpht.com/ytc/AIdro_lkEhXOgDq4ldY8xikcsEOfdYJ15wz7rhjI4Oxt_GObFlw=s800-c-k-c0xffffffff-no-rj-mo', 'default_language': None, 'country': None, 'uploads_playlist_id': None}, {'channel_id': 'UCl9eTaJHvf3U7eXPa7YKkTQ', 'channel_name': 'Murugesh Makeup Artist', 'channel_description': 'CERTIFIED MAKEUP ARTIST | HAIRSTYLIST ▪️BRIDAL ▪️SHOOTS ▪️CELEBRITY MUA ▪️MAKEUP EDUCATOR FOR ...', 'published_at': '2022-10-01T13:19:40Z', 'profile_picture_url': 'https://yt3.ggpht.com/X3osElTB-b6dQv5TRdUNZqQPzru9Zn_KDIq8wzJ0TGMsk_HsYmzt-3hLrCGNmGhkgYelTPz1=s800-c-k-c0xffffffff-no-rj-mo', 'default_language': None, 'country': None, 'uploads_playlist_id': None}, {'channel_id': 'UCpc2Jn8DTyNyOzriUK4abww', 'channel_name': 'Nishant Malik Makeup Artist ', 'channel_description': 'Hello viewers Welcome to Nishant Malik Makeup Artist Page Instagram id - nmmakeupofficial_ Nishant Malik Makeup Studio ...', 'published_at': '2016-06-09T15:04:40Z', 'profile_picture_url': 'https://yt3.ggpht.com/nur1pZQsgbrF-qFysbkcYCvL-U5s9PyVwJjmfsg865vVZJvg67hSdO9Hk3DYugCcwuwlXk7v=s800-c-k-c0xffffffff-no-rj-mo', 'default_language': None, 'country': None, 'uploads_playlist_id': None}]\n",
      "Found 50 new US channels from query 'makeup artist'.\n",
      "Fetching statistics, topic details, and branding settings for 50 channels...\n",
      "\n",
      "--- Total unique US channels found: 50 ---\n",
      "\n",
      "Processing channel 1/50: 'Judy D' (UCDLSt_KFcxWP-hsqAMuh0vg)\n",
      "Gemini thumbnail analysis failed: \"Unable to determine the intended type of the `dict`. For `Content`, a 'parts' key is expected. For `Part`, either an 'inline_data' or a 'text' key is expected. For `Blob`, both 'mime_type' and 'data' keys are expected. However, the provided dictionary has the following keys: ['mimeType', 'data']\"\n",
      "No sufficient content (description/transcripts) for LLM analysis for channel UCDLSt_KFcxWP-hsqAMuh0vg.\n",
      "Error inserting/updating channel data: table channels has no column named default_language\n",
      "\n",
      "Processing channel 2/50: 'Murugesh Makeup Artist' (UCl9eTaJHvf3U7eXPa7YKkTQ)\n",
      "Gemini thumbnail analysis failed: \"Unable to determine the intended type of the `dict`. For `Content`, a 'parts' key is expected. For `Part`, either an 'inline_data' or a 'text' key is expected. For `Blob`, both 'mime_type' and 'data' keys are expected. However, the provided dictionary has the following keys: ['mimeType', 'data']\"\n",
      "Error inserting/updating channel data: table channels has no column named default_language\n",
      "\n",
      "Processing channel 3/50: 'Nishant Malik Makeup Artist ' (UCpc2Jn8DTyNyOzriUK4abww)\n",
      "Gemini thumbnail analysis failed: \"Unable to determine the intended type of the `dict`. For `Content`, a 'parts' key is expected. For `Part`, either an 'inline_data' or a 'text' key is expected. For `Blob`, both 'mime_type' and 'data' keys are expected. However, the provided dictionary has the following keys: ['mimeType', 'data']\"\n",
      "Error inserting/updating channel data: table channels has no column named default_language\n",
      "\n",
      "Processing channel 4/50: 'Robert Welsh' (UC2GUcyD6KYjmU_ofQtPTSSA)\n",
      "Gemini thumbnail analysis failed: \"Unable to determine the intended type of the `dict`. For `Content`, a 'parts' key is expected. For `Part`, either an 'inline_data' or a 'text' key is expected. For `Blob`, both 'mime_type' and 'data' keys are expected. However, the provided dictionary has the following keys: ['mimeType', 'data']\"\n",
      "Error parsing Gemini response: Expecting value: line 1 column 1 (char 0). Raw text: Okay, I need the actual text content from the YouTube channel (description and recent video transcripts) to provide a meaningful analysis.  Without that content, I can only return a default JSON object with empty arrays.  Please provide the channel description and video transcripts, and I will populate the JSON object based on the guidance you provided.\n",
      "\n",
      "Here's the default JSON object assuming no content is provided:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"features_aligned_with\": [],\n",
      "  \"primary_makeup_style\": [],\n",
      "  \"target_skill_level\": [],\n",
      "  \"demographic_focus\": []\n",
      "}\n",
      "```\n",
      "\n",
      "Error inserting/updating channel data: table channels has no column named default_language\n",
      "\n",
      "Processing channel 5/50: 'Clarissa Makeup Artist' (UChJ1gs4RpGySr8qCVRNYgxg)\n",
      "Gemini thumbnail analysis failed: \"Unable to determine the intended type of the `dict`. For `Content`, a 'parts' key is expected. For `Part`, either an 'inline_data' or a 'text' key is expected. For `Blob`, both 'mime_type' and 'data' keys are expected. However, the provided dictionary has the following keys: ['mimeType', 'data']\"\n",
      "Error parsing Gemini response: Expecting value: line 1 column 1 (char 0). Raw text: Given the extremely limited text content (only a channel name and description mentioning \"Clarissa Make-up Artist\"), making definitive inferences is difficult. I will err on the side of caution and avoid making assumptions. Here's a plausible JSON response based on the available information:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"features_aligned_with\": [],\n",
      "  \"primary_makeup_style\": [],\n",
      "  \"target_skill_level\": [],\n",
      "  \"demographic_focus\": []\n",
      "}\n",
      "```\n",
      "\n",
      "**Explanation:**\n",
      "\n",
      "*   **features_aligned_with:** Insufficient information to determine any specific facial features or skin types.\n",
      "*   **primary_makeup_style:** The channel name suggests makeup artistry, but doesn't specify a particular style (glam, natural, etc.).\n",
      "*   **target_skill_level:**  Cannot be determined without video content analysis.\n",
      "*   **demographic_focus:** The channel name and limited description provide no demographic clues.\n",
      "\n",
      "Error inserting/updating channel data: table channels has no column named default_language\n",
      "\n",
      "Processing channel 6/50: 'MJ makeup artist 1234' (UCHZBvhmGhnpJF4Q3YZGPz8g)\n",
      "Gemini thumbnail analysis failed: \"Unable to determine the intended type of the `dict`. For `Content`, a 'parts' key is expected. For `Part`, either an 'inline_data' or a 'text' key is expected. For `Blob`, both 'mime_type' and 'data' keys are expected. However, the provided dictionary has the following keys: ['mimeType', 'data']\"\n",
      "Error inserting/updating channel data: table channels has no column named default_language\n",
      "\n",
      "Processing channel 7/50: 'Sadia Makeup Artist' (UCHXWTLYx6W_-SNKbfF3QkGA)\n",
      "Gemini thumbnail analysis failed: \"Unable to determine the intended type of the `dict`. For `Content`, a 'parts' key is expected. For `Part`, either an 'inline_data' or a 'text' key is expected. For `Blob`, both 'mime_type' and 'data' keys are expected. However, the provided dictionary has the following keys: ['mimeType', 'data']\"\n",
      "No sufficient content (description/transcripts) for LLM analysis for channel UCHXWTLYx6W_-SNKbfF3QkGA.\n",
      "Error inserting/updating channel data: table channels has no column named default_language\n",
      "\n",
      "Processing channel 8/50: 'Quach Anh Makeup Artist' (UCHQO9xPSROEHYHUk_T82l6w)\n",
      "Gemini thumbnail analysis failed: \"Unable to determine the intended type of the `dict`. For `Content`, a 'parts' key is expected. For `Part`, either an 'inline_data' or a 'text' key is expected. For `Blob`, both 'mime_type' and 'data' keys are expected. However, the provided dictionary has the following keys: ['mimeType', 'data']\"\n",
      "Error inserting/updating channel data: table channels has no column named default_language\n",
      "\n",
      "Processing channel 9/50: 'Your Favourite Makeup Artist' (UC4K6dQInBoTG3lWv7ySqhZA)\n",
      "Gemini thumbnail analysis failed: \"Unable to determine the intended type of the `dict`. For `Content`, a 'parts' key is expected. For `Part`, either an 'inline_data' or a 'text' key is expected. For `Blob`, both 'mime_type' and 'data' keys are expected. However, the provided dictionary has the following keys: ['mimeType', 'data']\"\n",
      "Error inserting/updating channel data: table channels has no column named default_language\n",
      "\n",
      "Processing channel 10/50: 'Reema Khan Makeup Artist' (UC3KP6dvAauZp5ilgg3GS8RQ)\n",
      "Gemini thumbnail analysis failed: \"Unable to determine the intended type of the `dict`. For `Content`, a 'parts' key is expected. For `Part`, either an 'inline_data' or a 'text' key is expected. For `Blob`, both 'mime_type' and 'data' keys are expected. However, the provided dictionary has the following keys: ['mimeType', 'data']\"\n",
      "Error parsing Gemini response: Expecting value: line 1 column 1 (char 0). Raw text: Based on the provided limited text content (only the channel description introduction is present), it's impossible to accurately infer the specific features aligned with, primary makeup style, target skill level, or demographic focus.  The content is too generic. Therefore, I will return empty arrays for all categories.\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"features_aligned_with\": [],\n",
      "  \"primary_makeup_style\": [],\n",
      "  \"target_skill_level\": [],\n",
      "  \"demographic_focus\": []\n",
      "}\n",
      "```\n",
      "\n",
      "Error inserting/updating channel data: table channels has no column named default_language\n",
      "\n",
      "Processing channel 11/50: 'Asmaa Adel makeup artist' (UCjwERJDotcRLaXakJADlCXw)\n",
      "Gemini thumbnail analysis failed: \"Unable to determine the intended type of the `dict`. For `Content`, a 'parts' key is expected. For `Part`, either an 'inline_data' or a 'text' key is expected. For `Blob`, both 'mime_type' and 'data' keys are expected. However, the provided dictionary has the following keys: ['mimeType', 'data']\"\n",
      "Error inserting/updating channel data: table channels has no column named default_language\n",
      "\n",
      "Processing channel 12/50: 'Zoë ASMR makeup artist' (UColpMuiLe9_vtmZPHFK-WvQ)\n",
      "Gemini thumbnail analysis failed: \"Unable to determine the intended type of the `dict`. For `Content`, a 'parts' key is expected. For `Part`, either an 'inline_data' or a 'text' key is expected. For `Blob`, both 'mime_type' and 'data' keys are expected. However, the provided dictionary has the following keys: ['mimeType', 'data']\"\n",
      "Error inserting/updating channel data: table channels has no column named default_language\n",
      "\n",
      "Processing channel 13/50: 'Kavya makeupartist ' (UCif5BkqPLF4eFstYeOGeNUQ)\n",
      "Gemini thumbnail analysis failed: \"Unable to determine the intended type of the `dict`. For `Content`, a 'parts' key is expected. For `Part`, either an 'inline_data' or a 'text' key is expected. For `Blob`, both 'mime_type' and 'data' keys are expected. However, the provided dictionary has the following keys: ['mimeType', 'data']\"\n",
      "Error inserting/updating channel data: table channels has no column named default_language\n",
      "\n",
      "Processing channel 14/50: 'Makeup By Nikki La Rose' (UCCydBRF6RjrT58FV6KO-wwg)\n",
      "Gemini thumbnail analysis failed: \"Unable to determine the intended type of the `dict`. For `Content`, a 'parts' key is expected. For `Part`, either an 'inline_data' or a 'text' key is expected. For `Blob`, both 'mime_type' and 'data' keys are expected. However, the provided dictionary has the following keys: ['mimeType', 'data']\"\n",
      "Error parsing Gemini response: Expecting value: line 1 column 1 (char 0). Raw text: Okay, based on the provided text content, here's the JSON object representing the analysis of the YouTube channel:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"features_aligned_with\": [],\n",
      "  \"primary_makeup_style\": [\"editorial\"],\n",
      "  \"target_skill_level\": [\"beginner\", \"intermediate\", \"advanced\"],\n",
      "  \"demographic_focus\": []\n",
      "}\n",
      "```\n",
      "\n",
      "Error inserting/updating channel data: table channels has no column named default_language\n",
      "\n",
      "Processing channel 15/50: 'Karolina Zientek MakeUp Artist' (UC_WmI554ltRf2hwzTqhWy4Q)\n",
      "Gemini thumbnail analysis failed: \"Unable to determine the intended type of the `dict`. For `Content`, a 'parts' key is expected. For `Part`, either an 'inline_data' or a 'text' key is expected. For `Blob`, both 'mime_type' and 'data' keys are expected. However, the provided dictionary has the following keys: ['mimeType', 'data']\"\n",
      "Error inserting/updating channel data: table channels has no column named default_language\n",
      "\n",
      "Processing channel 16/50: 'Shahlabacker Makeup Artist' (UCru67MQuuq-hbbidUXT6CYA)\n",
      "Gemini thumbnail analysis failed: \"Unable to determine the intended type of the `dict`. For `Content`, a 'parts' key is expected. For `Part`, either an 'inline_data' or a 'text' key is expected. For `Blob`, both 'mime_type' and 'data' keys are expected. However, the provided dictionary has the following keys: ['mimeType', 'data']\"\n",
      "Error inserting/updating channel data: table channels has no column named default_language\n",
      "\n",
      "Processing channel 17/50: 'Tony The Makeup Artist' (UCk_Fes1FHP_x7omhO7DmnPQ)\n",
      "Gemini thumbnail analysis failed: \"Unable to determine the intended type of the `dict`. For `Content`, a 'parts' key is expected. For `Part`, either an 'inline_data' or a 'text' key is expected. For `Blob`, both 'mime_type' and 'data' keys are expected. However, the provided dictionary has the following keys: ['mimeType', 'data']\"\n",
      "Error parsing Gemini response: Expecting value: line 1 column 1 (char 0). Raw text: Based on the provided text content, here's the JSON object representing the analysis of the YouTube channel:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"features_aligned_with\": [],\n",
      "  \"primary_makeup_style\": [],\n",
      "  \"target_skill_level\": [],\n",
      "  \"demographic_focus\": []\n",
      "}\n",
      "```\n",
      "\n",
      "**Explanation:**\n",
      "\n",
      "*   **features_aligned_with:** The text doesn't provide specific details about facial features, skin types, or undertones that the channel focuses on. Thus, the array is empty.\n",
      "*   **primary_makeup_style:** The description mentions \"all types of makeups,\" but doesn't emphasize any particular style like glam, natural, or editorial. Hence, it's an empty array.\n",
      "*   **target_skill_level:** The channel's description, while stating expertise, doesn't explicitly target a particular skill level (beginner, intermediate, etc.).Therefore, the array is empty.\n",
      "*   **demographic_focus:** The description doesn't specify a particular demographic focus (teen, mature, skin tones, etc.). Thus, the array remains empty.\n",
      "\n",
      "Error inserting/updating channel data: table channels has no column named default_language\n",
      "\n",
      "Processing channel 18/50: '  Makeup Artist ' (UCz1HJ03TVULAEgYm8UgSHKg)\n",
      "Gemini thumbnail analysis failed: \"Unable to determine the intended type of the `dict`. For `Content`, a 'parts' key is expected. For `Part`, either an 'inline_data' or a 'text' key is expected. For `Blob`, both 'mime_type' and 'data' keys are expected. However, the provided dictionary has the following keys: ['mimeType', 'data']\"\n",
      "Error inserting/updating channel data: table channels has no column named default_language\n",
      "\n",
      "Processing channel 19/50: 'Makeup Artist Payel Sinha Halder' (UCn84tkreBkUQS50GUAAV-ig)\n",
      "Gemini thumbnail analysis failed: \"Unable to determine the intended type of the `dict`. For `Content`, a 'parts' key is expected. For `Part`, either an 'inline_data' or a 'text' key is expected. For `Blob`, both 'mime_type' and 'data' keys are expected. However, the provided dictionary has the following keys: ['mimeType', 'data']\"\n",
      "Gemini content analysis failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 35\n",
      "}\n",
      "]\n",
      "Error inserting/updating channel data: table channels has no column named default_language\n",
      "\n",
      "Processing channel 20/50: 'monica sobhy makeup artist' (UCRi278WPXTFmmcf8taOg_vA)\n",
      "Gemini thumbnail analysis failed: \"Unable to determine the intended type of the `dict`. For `Content`, a 'parts' key is expected. For `Part`, either an 'inline_data' or a 'text' key is expected. For `Blob`, both 'mime_type' and 'data' keys are expected. However, the provided dictionary has the following keys: ['mimeType', 'data']\"\n",
      "Error inserting/updating channel data: table channels has no column named default_language\n",
      "\n",
      "Processing channel 21/50: 'Mukul Richards Makeup Artist' (UC7h9Hhv4Unc2lUMCIpMKG-A)\n",
      "Gemini thumbnail analysis failed: \"Unable to determine the intended type of the `dict`. For `Content`, a 'parts' key is expected. For `Part`, either an 'inline_data' or a 'text' key is expected. For `Blob`, both 'mime_type' and 'data' keys are expected. However, the provided dictionary has the following keys: ['mimeType', 'data']\"\n",
      "Error inserting/updating channel data: table channels has no column named default_language\n",
      "\n",
      "Processing channel 22/50: 'Waad Makeup Artist' (UCQhBchX4GuCRr9OUc-arXVw)\n",
      "Gemini thumbnail analysis failed: \"Unable to determine the intended type of the `dict`. For `Content`, a 'parts' key is expected. For `Part`, either an 'inline_data' or a 'text' key is expected. For `Blob`, both 'mime_type' and 'data' keys are expected. However, the provided dictionary has the following keys: ['mimeType', 'data']\"\n",
      "No sufficient content (description/transcripts) for LLM analysis for channel UCQhBchX4GuCRr9OUc-arXVw.\n",
      "Error inserting/updating channel data: table channels has no column named default_language\n",
      "\n",
      "Processing channel 23/50: 'Vikas Vks Makeup artist' (UCo3fUW2rnvrTSyIFJZsetUg)\n",
      "Gemini thumbnail analysis failed: \"Unable to determine the intended type of the `dict`. For `Content`, a 'parts' key is expected. For `Part`, either an 'inline_data' or a 'text' key is expected. For `Blob`, both 'mime_type' and 'data' keys are expected. However, the provided dictionary has the following keys: ['mimeType', 'data']\"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[71]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     run_channel_ingestion()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[70]\u001b[39m\u001b[32m, line 136\u001b[39m, in \u001b[36mrun_channel_ingestion\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    134\u001b[39m     channel[\u001b[33m'\u001b[39m\u001b[33mtarget_skill_level\u001b[39m\u001b[33m'\u001b[39m] = json.dumps(content_llm_attrs[\u001b[33m'\u001b[39m\u001b[33mtarget_skill_level\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m    135\u001b[39m     channel[\u001b[33m'\u001b[39m\u001b[33mdemographic_focus\u001b[39m\u001b[33m'\u001b[39m] = json.dumps(content_llm_attrs[\u001b[33m'\u001b[39m\u001b[33mdemographic_focus\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m     time.sleep(\u001b[32m1\u001b[39m) \u001b[38;5;66;03m# Small delay for Gemini Text API\u001b[39;00m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    138\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo sufficient content (description/transcripts) for LLM analysis for channel \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchannel_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    run_channel_ingestion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "process_1 = np.random.random(size=10**7)\n",
    "process_2 = np.random.random(size=10**7)\n",
    "overlap_percentage = np.mean(np.abs(process_1 - process_2) <= 0.20)\n",
    "annual_cost = overlap_percentage * 365 * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131406.97149999999"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annual_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
