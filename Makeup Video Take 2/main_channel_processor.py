# -*- coding: utf-8 -*-
"""main_channel_processor.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MO02BnH4tUmUmEmBYu8Ew2GjRt2t0ml-
"""

# !pip install youtube_transcript_api

# main_channel_processor.py
"""
Main script for the YouTube Channel Data Ingestion and LLM Analysis.

This script orchestrates the entire process:
1. Searches for YouTube channels based on predefined queries.
2. Fetches detailed statistics and video information for selected channels.
3. Analyzes channel profile pictures (thumbnails) and content (descriptions/transcripts)
   using Google Gemini AI to infer specific makeup-related attributes.
4. Displays the comprehensive data and LLM-inferred attributes for each channel.
"""

import random
import time
from datetime import datetime, timezone
import sys # For checking python version
import google.generativeai as genai


# Import functions and configurations from modular files
from config import SEARCH_QUERIES, PREDEFINED_CATEGORIES, YOUTUBE_API_KEY, GEMINI_API_KEY
print(YOUTUBE_API_KEY)
print(GEMINI_API_KEY)
from youtube_api_utils import (
    get_youtube_service,
    search_youtube_channels,
    get_channel_statistics_and_topics,
    get_last_video_upload_timestamp,
    get_video_transcripts
)
from gemini_ai_utils import (
    get_image_as_pil_image,
    analyze_thumbnail_with_gemini,
    analyze_content_with_gemini
)

def run_channel_ingestion_and_analysis():
    """
    Executes the full pipeline for YouTube channel data ingestion and LLM analysis.
    """
    print(f"Python version: {sys.version}")
    print(f"genai version: {genai.__version__}") # Confirm genai version during runtime

    # Check if API keys are set
    if YOUTUBE_API_KEY == "YOUR_YOUTUBE_API_KEY" or GEMINI_API_KEY == "YOUR_GEMINI_API_KEY":
        print("\nERROR: Please set your YOUTUBE_API_KEY and GEMINI_API_KEY in config.py before running.")
        return

    youtube = get_youtube_service()

    all_channels_data = {}
    channels_to_display = [] # List to hold up to 5 unique channels for detailed processing

    # Step 1: Search for channels and collect up to 5 unique US-centric channels
    shuffled_queries = random.sample(SEARCH_QUERIES, len(SEARCH_QUERIES))

    print("--- Starting Channel Search and Collection ---")
    for query in shuffled_queries:
        if len(channels_to_display) >= 5: # Limit to 5 channels for display
            break
        print(f"\nSearching for channels with query: '{query}'...")
        found_channels_for_query = search_youtube_channels(youtube, query, max_results=50)

        for channel in found_channels_for_query:
            # Ensure uniqueness and US-centric (or unspecified country)
            if (channel.get('country') == 'US' or channel.get('country') is None) and channel['channel_id'] not in all_channels_data:
                # Initialize channel data structure
                all_channels_data[channel['channel_id']] = {
                    'channel_id': channel['channel_id'],
                    'channel_name': channel['channel_name'],
                    'channel_url': f"https://www.youtube.com/channel/{channel['channel_id']}",
                    'channel_description': channel['channel_description'],
                    'published_at': channel['published_at'],
                    'profile_picture_url': channel['profile_picture_url'],
                    'country': channel['country'],
                    'default_language': channel['default_language'],
                    'keywords': [], # Will be populated later
                    'subscriber_count': 0,
                    'video_count': 0,
                    'total_view_count': 0,
                    'topic_ids': [], # Will be populated later
                    'last_content_upload_at': None,
                    'last_updated': datetime.now(timezone.utc).isoformat(),
                    'features_aligned_with': [],
                    'primary_makeup_style': [],
                    'target_skill_level': [],
                    'demographic_focus': [],
                    'llm_thumbnail_face_shape': "unknown",
                    'llm_thumbnail_skin_color': "unknown",
                    'llm_thumbnail_eye_shape': "unknown",
                    'llm_thumbnail_lip_shape': "unknown",
                    'llm_thumbnail_status': "pending",
                    'llm_thumbnail_analysis_date': None
                }
                channels_to_display.append(all_channels_data[channel['channel_id']])
            if len(channels_to_display) >= 5:
                break
        time.sleep(0.5) # Pause to respect API limits

    print(f"\n--- Found {len(channels_to_display)} unique channels for detailed analysis and display ---\n")

    # Step 2: Fetch detailed statistics for collected channels in a batch
    channel_ids_for_batch = [c['channel_id'] for c in channels_to_display]
    if channel_ids_for_batch:
        print(f"Fetching statistics, topic details, and branding settings for {len(channel_ids_for_batch)} channels...")
        batch_details = get_channel_statistics_and_topics(youtube, channel_ids_for_batch)
        for channel_id, details in batch_details.items():
            if channel_id in all_channels_data:
                all_channels_data[channel_id].update({
                    'subscriber_count': details['subscriber_count'],
                    'video_count': details['video_count'],
                    'total_view_count': details['total_view_count'],
                    'topic_ids': details['topic_ids'],
                    'keywords': details['keywords']
                })
                # Fetch last upload timestamp if uploads playlist ID is available
                last_upload = get_last_video_upload_timestamp(youtube, details['uploads_playlist_id'])
                all_channels_data[channel_id]['last_content_upload_at'] = last_upload
                # Update the uploads_playlist_id in the main channel data structure
                all_channels_data[channel_id]['uploads_playlist_id'] = details['uploads_playlist_id']
        time.sleep(0.1) # Small pause

    # Step 3 & 4: Process each channel, perform LLM analysis, and display results
    for i, channel in enumerate(channels_to_display):
        channel_name = channel.get('channel_name', 'Unknown Channel')
        channel_id = channel['channel_id']
        channel_description = channel.get('channel_description', '')
        uploads_playlist_id = channel.get('uploads_playlist_id')

        print(f"\n--- Displaying Channel {i+1}/{len(channels_to_display)}: '{channel_name}' ({channel_id}) ---")
        print(f"Channel URL: {channel['channel_url']}")
        print(f"Profile Picture: {channel['profile_picture_url']}")
        print(f"Subscribers: {channel['subscriber_count']}")
        print(f"Total Videos: {channel['video_count']}")
        print(f"Total Views: {channel['total_view_count']}")
        print(f"Country: {channel['country']}")
        print(f"Default Language: {channel['default_language']}")
        print(f"Keywords: {channel['keywords']}")
        print(f"Last Content Upload: {channel['last_content_upload_at']}")
        print(f"Last Updated (Script): {channel['last_updated']}")
        print("\nChannel Description:")
        print(channel_description[:500] + "..." if len(channel_description) > 500 else channel_description)

        # Fetch video transcripts for content analysis
        transcripts_sample_text = []
        if uploads_playlist_id:
            try:
                playlist_items_response = youtube.playlistItems().list(
                    part='snippet',
                    playlistId=uploads_playlist_id,
                    maxResults=5, # Fetch transcripts for up to 5 recent videos
                    fields='items/snippet/resourceId/videoId,items/snippet/title'
                ).execute()

                recent_videos = playlist_items_response.get('items', [])
                print(f"\nFetching transcripts for {len(recent_videos)} recent videos:")
                for vid_item in recent_videos:
                    video_id = vid_item['snippet']['resourceId']['videoId']
                    video_title = vid_item['snippet']['title']
                    print(f"  - Video: '{video_title}' (ID: {video_id})")
                    transcript = get_video_transcripts(video_id)
                    if transcript:
                        transcripts_sample_text.append(transcript)
                        print(f"    Transcript fetched. Length: {len(transcript)} chars.")
                    else:
                        print("    No English transcript available or error.")
                    time.sleep(0.5) # Pause to respect API limits
            except Exception as e:
                print(f"Error getting recent videos for {channel_name}: {e}")
        else:
            print("No uploads playlist ID available or error fetching for this channel.")

        # --- Gemini Content (Transcript) Analysis ---
        print("\n--- Sending combined content to Gemini for analysis... ---")
        content_llm_attrs = analyze_content_with_gemini(
            channel_description, "\n".join(transcripts_sample_text)
        )
        channel['features_aligned_with'] = content_llm_attrs['features_aligned_with']
        channel['primary_makeup_style'] = content_llm_attrs['primary_makeup_style']
        channel['target_skill_level'] = content_llm_attrs['target_skill_level']
        channel['demographic_focus'] = content_llm_attrs['demographic_focus']
        time.sleep(1) # Pause to respect API limits

        print("\n--- LLM Inferred Attributes (Content) ---")
        print(f"  Features Aligned With: {channel['features_aligned_with']}")
        print(f"  Primary Makeup Style: {channel['primary_makeup_style']}")
        print(f"  Target Skill Level: {channel['target_skill_level']}")
        print(f"  Demographic Focus: {channel['demographic_focus']}")
        print("------------------------------------------")

        # --- Gemini Thumbnail Analysis ---
        thumbnail_url = channel['profile_picture_url']
        pil_image = get_image_as_pil_image(thumbnail_url)
        if pil_image:
            thumbnail_llm_attrs = analyze_thumbnail_with_gemini(pil_image)
            channel['llm_thumbnail_face_shape'] = thumbnail_llm_attrs['llm_thumbnail_face_shape']
            channel['llm_thumbnail_skin_color'] = thumbnail_llm_attrs['llm_thumbnail_skin_color']
            channel['llm_thumbnail_eye_shape'] = thumbnail_llm_attrs['llm_thumbnail_eye_shape']
            channel['llm_thumbnail_lip_shape'] = thumbnail_llm_attrs['llm_thumbnail_lip_shape']
            channel['llm_thumbnail_status'] = thumbnail_llm_attrs['llm_thumbnail_status']
            channel['llm_thumbnail_analysis_date'] = datetime.now(timezone.utc).isoformat()
            time.sleep(1) # Pause to respect API limits
            print("\n--- LLM Inferred Attributes (Thumbnail) ---")
            print(f"  Face Shape: {channel['llm_thumbnail_face_shape']}")
            print(f"  Skin Color: {channel['llm_thumbnail_skin_color']}")
            print(f"  Eye Shape: {channel['llm_thumbnail_eye_shape']}")
            print(f"  Lip Shape: {channel['llm_thumbnail_lip_shape']}")
            print(f"  Status: {channel['llm_thumbnail_status']}")
            print("------------------------------------------")
        else:
            print("\n--- LLM Inferred Attributes (Thumbnail) ---")
            print("  Skipped due to image processing error or no image.")
            print("------------------------------------------")

        print("\n" + "="*80 + "\n") # Separator for channels
        time.sleep(0.2)

    print("\n--- Channel data analysis and display complete! ---")

if __name__ == "__main__":
    run_channel_ingestion_and_analysis()

"""# New Section"""